{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMBA94aXwH0H"
      },
      "source": [
        "# Install deps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieoB_idcwOWB",
        "outputId": "42c25b45-4ef2-4497-96cc-1e71f30467d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip3 install -U torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "eG7pgWg8OAoF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 8:\n",
        "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0W1FUZV5wH0I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "PROJECT = \"unsplot-mistral7b-lpr\"\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"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\"\n",
        "os.environ[\"BACKUP_DIR\"] = \"/content/drive/MyDrive/WIP\"\n",
        "os.environ[\"VERSION\"] = PROJECT\n",
        "\n",
        "os.environ[\"WANDB_PROJECT\"] = \"kaggle-lpr\"  # name your W&B project\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"unsloth_mistral-it-7b\"  # log all model checkpoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rznuwneiOCm5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# !pip install -U -q sentence-transformers\n",
        "# !pip install -U -q wandb\n",
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UYiWzf19U442"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from unsloth import FastLanguageModel\n",
        "# from peft import PeftModel\n",
        "import re\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Utils function\n",
        "t5base_model = None\n",
        "\n",
        "# Function to calculate sharpened cosine similarity\n",
        "def sharpened_cosine_similarity(vec1, vec2, exponent=3):\n",
        "    cosine_similarity = torch.nn.functional.cosine_similarity(vec1, vec2, dim=0)\n",
        "    return cosine_similarity ** exponent\n",
        "\n",
        "#provides similarity scores of a test_phrase against an array of phrases\n",
        "def compare_phrases(test_phrase, phrases):\n",
        "    global t5base_model\n",
        "    t5base_model = SentenceTransformer('sentence-t5-base')\n",
        "    if torch.cuda.is_available():\n",
        "        t5base_model = t5base_model.to(torch.device(\"cuda\"))\n",
        "    model = t5base_model\n",
        "\n",
        "    scores = []\n",
        "    test_embedding = model.encode(test_phrase, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "    for phrase in phrases:\n",
        "        compare_embedding = model.encode(phrase, convert_to_tensor=True, show_progress_bar=False)\n",
        "        score = sharpened_cosine_similarity(test_embedding, compare_embedding).item()\n",
        "        scores.append(score)\n",
        "\n",
        "    return scores\n",
        "\n",
        "def truncate_sentence(text, max_words):\n",
        "    if not isinstance(text, str):\n",
        "        print(text)\n",
        "    words = text.split(\" \")\n",
        "    if len(words) <= max_words:\n",
        "        return text\n",
        "    return \" \".join(words[:max_words])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jmKnYQkHVBE7"
      },
      "outputs": [],
      "source": [
        "# Model prompt builder\n",
        "class MistralInstructPromptBuilder:\n",
        "    # instruction = \"\"\"You are an AI assistant capable of aiding my comprehension of modifications made to a given text compared to the original, all within a single 30-word sentence. Avoid specific thoughts, then provide a 30-word rewrite prompt for transformation.\"\"\"\n",
        "    instruction = \"\"\"You are an AI assistant capable of aiding my comprehension regarding changes in tone, style, and vocabulary between a modified text and its original, without specifics in content alterations. Provide a 30-word rewrite prompt for transformation.\"\"\"\n",
        "    def create_train_row(self, original_text, rewritten_text, rewrite_prompt):\n",
        "        original_text = truncate_sentence(original_text, 200)\n",
        "        rewritten_text = truncate_sentence(rewritten_text, 200)\n",
        "        rewrite_prompt = truncate_sentence(rewrite_prompt, 200)\n",
        "        input = f\"**Original Text:** {original_text}\\n**Rewritten Text:** {rewritten_text}\"\n",
        "        output = f\"**Rewrite Prompt:** {rewrite_prompt}\"\n",
        "        text_row = f\"\"\"<s>[INST] {self.instruction} Here are the inputs\\n{input} [/INST] \\\\n {output} </s>\"\"\"\n",
        "        return text_row\n",
        "\n",
        "    def create_test_row(self, original_text, rewritten_text):\n",
        "        original_text = truncate_sentence(original_text, 200)\n",
        "        rewritten_text = truncate_sentence(rewritten_text, 200)\n",
        "        input = f\"**Original Text:** {original_text}\\n**Rewritten Text:** {rewritten_text}\"\n",
        "        text_row = f\"\"\"<s>[INST] {self.instruction} Here are the inputs\\n{input} [/INST]\"\"\"\n",
        "        return text_row\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PrMLjOEWwH0I"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "class PRModel:\n",
        "    def __init__(self,\n",
        "                 model=None, tokenizer=None,\n",
        "                 model_name=None,\n",
        "                 prompt_builder=None,\n",
        "                 init_peft=False,\n",
        "                 device=None):\n",
        "        d = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        if device is None:\n",
        "            device = d\n",
        "        self.device = device\n",
        "        self.prompt_builder = prompt_builder\n",
        "        self.infer_max_new_tokens = 100\n",
        "\n",
        "        max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "        dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "        load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "        if model and tokenizer:\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "        else:\n",
        "            model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "                model_name = model_name, # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
        "                max_seq_length = max_seq_length,\n",
        "                dtype = dtype,\n",
        "                load_in_4bit = load_in_4bit,\n",
        "                # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        "            )\n",
        "\n",
        "            if init_peft:\n",
        "                model = FastLanguageModel.get_peft_model(\n",
        "                    model,\n",
        "                    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "                    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                                    \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "                    lora_alpha = 16,\n",
        "                    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "                    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "                    use_gradient_checkpointing = True,\n",
        "                    random_state = 3407,\n",
        "                    use_rslora = False,  # We support rank stabilized LoRA\n",
        "                    loftq_config = None, # And LoftQ\n",
        "                )\n",
        "\n",
        "            self.model = model\n",
        "            self.tokenizer = tokenizer\n",
        "\n",
        "    def eval(self):\n",
        "        FastLanguageModel.for_inference(self.model) # Enable native 2x faster inference\n",
        "\n",
        "    def predict_prompt(self, original_text, rewritten_text):\n",
        "        inputs = self.tokenizer(\n",
        "        [\n",
        "            self.prompt_builder.create_test_row(original_text, rewritten_text),\n",
        "        ], return_tensors = \"pt\").to(self.device)\n",
        "\n",
        "        outputs = self.model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=self.infer_max_new_tokens,\n",
        "            use_cache = True\n",
        "        )\n",
        "        outputs = [outputs[0][len(inputs[\"input_ids\"][0]):], ]\n",
        "        predict = self.tokenizer.batch_decode(outputs, skip_special_tokens = True)[0]\n",
        "\n",
        "        predict = predict.replace(\"\\\\n\", \"\\n\")\n",
        "        predict = re.sub(r\"^\\s+|\\s+$\", \"\", predict)\n",
        "        if predict.startswith(\"**Rewrite Prompt:**\"):\n",
        "            predict = predict[len(\"**Rewrite Prompt:**\"):].strip()\n",
        "        return predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-lqGPVIwH0J"
      },
      "source": [
        "# 1. Prepare data & train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wenca97rwH0J",
        "outputId": "0913dc86-7873-427e-89bd-6e75960d71a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3200, 5) (800, 5)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# data\n",
        "DATA_DIR = Path(\"/datasets/llm_prompt_recovery/\")\n",
        "CKPT_DIR = Path(\"./\")\n",
        "\n",
        "# load data\n",
        "train_df = pd.read_csv(DATA_DIR / \"train_data.csv\")\n",
        "test_df = pd.read_csv(DATA_DIR / \"test_data.csv\")\n",
        "# train_df.dropna(inplace=True)\n",
        "\n",
        "print(train_df.shape, test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "id": "csqO_9hwgTFa",
        "outputId": "a04f4481-4a15-4b56-d6d3-40e1abf8a0c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s>[INST] You are an AI assistant capable of aiding my comprehension of modifications made to a given text compared to the original, all within a single 30-word sentence. Avoid specific thoughts, then provide a 30-word rewrite prompt for transformation. Here are the inputs\\n**Original Text:** Hot tears rapidly stream from my eyes. As the shuddering sobs eventually subside, I am a weakened heap on the bed. A familiar coldness seeps out of the dark, deep corners of my mind and threatens to destroy everything it touches. Suddenly, the coldness draws back, and there is warmth. I look to the doorway and he is standing there. I see him, and there is no greater sight. He wipes away my tears and, with them, the burdens that threatened to consume me. He holds me, and his love heals my marred soul until I am bright and new again.\\n\\n**Rewritten Text:** The hot tears rapidly stream from my eyes. As the shuddering sobs eventually subside, I am a weakened heap on the bed. A familiar bitterness permeates the air, choking me with its acrid odor. Suddenly, the bitterness fades, and there is sweetness. I look to the doorway and he is standing there. I see him, and there is no greater sight. He wipes away my tears and, with them, the burdens that threatened to consume me. He holds me, and his hate heals my marred soul until I am bitter and broken again. [/INST] \\\\n **Rewrite Prompt:** Rewrite the essay , but shift it in a way that the things you are describing are actually ugly </s>'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MistralInstructPromptBuilder().create_train_row(\n",
        "    train_df.iloc[0]['original_text'],\n",
        "    train_df.iloc[0]['rewritten_text'],\n",
        "    train_df.iloc[0]['rewrite_prompt'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st6UcpohwH0J"
      },
      "source": [
        "2. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "229cc36fd7e149179c074beac1c05ef6",
            "8e92d73ea8b54131b3b28e6e8ecb7a77",
            "a1e61850f5f247d0ab7be7094a810dc5",
            "b2b1404b24fa444eb2659caa7b23e5de",
            "ff45296d59534ec58ceb575f7e39f49a",
            "68825f73bbcc4727b8c0c932bfdb9f57",
            "30dec4651d0346af9e392ad046d5c8c9",
            "99ee65ae8bff466883dbb966bcb55535",
            "7903e8c3d41740f195ed572f5e5bf2cd",
            "f674070c3f0e4f3695c4c887dcfd2c3a",
            "6cb6b4fb9c60402cbbd67c4bc29e8f7c",
            "eb1f379fc16e491b9743001bc07abd97",
            "c6b57bb8140f49179dfa87129762225e",
            "aebb3b43ccc4440eb831be56cfe19e4b",
            "03333a9a70f84554b5f11e4490479a74",
            "406b2b5a9370425292ff9998a23d9bb8",
            "5e65d58da69d4b21af89afec22c8fe43",
            "c90d0970929948c7962cc8e792936bb0",
            "7770d1198f0c40ddaae32f36fd4e7bda",
            "9788b0e1560845538632289840f9ca3e",
            "b6a77e76130846ce8b771165ad97f18d",
            "7e788bbba0864102ad4d4ac49ff6da18"
          ]
        },
        "id": "QXDmy5X-Zu8N",
        "outputId": "9bce82e1-80a6-463d-f282-a9fd3941c0fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.3\n",
            "   \\\\   /|    GPU: Tesla V100-SXM2-16GB. Max memory: 15.773 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.0. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Unsloth 2024.3 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "229cc36fd7e149179c074beac1c05ef6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb1f379fc16e491b9743001bc07abd97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/3200 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from datasets import Dataset\n",
        "\n",
        "import gc\n",
        "import torch\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "prompt_builder = MistralInstructPromptBuilder()\n",
        "prmodel = PRModel(\n",
        "    model_name=\"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "    # adapter_model_name = CKPT_DIR / PROJECT_NAME,\n",
        "    prompt_builder = prompt_builder,\n",
        "    init_peft=True,\n",
        ")\n",
        "\n",
        "model, tokenizer = prmodel.model, prmodel.tokenizer\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    original_texts = examples[\"original_text\"]\n",
        "    rewritten_texts = examples[\"rewritten_text\"]\n",
        "    rewrite_prompts = examples[\"rewrite_prompt\"]\n",
        "\n",
        "    texts = []\n",
        "    for original_text, rewritten_text, rewrite_prompt in zip(original_texts, rewritten_texts, rewrite_prompts):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = prompt_builder.create_train_row(original_text, rewritten_text, rewrite_prompt) + tokenizer.eos_token\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "dataset = Dataset.from_pandas(train_df)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
        "\n",
        "max_seq_length = 2048\n",
        "n_epochs = 1\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        report_to=\"wandb\",\n",
        "        per_device_train_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # max_steps = 60,\n",
        "        num_train_epochs=n_epochs,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R_GkmEtqcMw8",
        "outputId": "4384ee77-cfb2-4bcd-f111-b9737c32fd23"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 3,200 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 16 | Total steps = 200\n",
            " \"-____-\"     Number of trainable parameters = 41,943,040\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdungvu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240320_170007-pfskkcxg</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dungvu/kaggle-lpr/runs/pfskkcxg' target=\"_blank\">frosty-hill-3</a></strong> to <a href='https://wandb.ai/dungvu/kaggle-lpr' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/dungvu/kaggle-lpr' target=\"_blank\">https://wandb.ai/dungvu/kaggle-lpr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/dungvu/kaggle-lpr/runs/pfskkcxg' target=\"_blank\">https://wandb.ai/dungvu/kaggle-lpr/runs/pfskkcxg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/200 15:49 < 09:39, 0.13 it/s, Epoch 0.62/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.186800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.165400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.074600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.621900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.418900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.172400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.226000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.146000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.854900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.897100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.740400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.845300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.822400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.726800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.689500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.756600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.655800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.795700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.657700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.690700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.762600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.648700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.714600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.635700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.576900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.621000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.673300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.634800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.569500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.669100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.678400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.572400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.550800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.732700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.715000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.520900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.592100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.606200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.677100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.560500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.570100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.581100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.519700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.649200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.575000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.548000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.626400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.607800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.577800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.694000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.516700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.488200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.437600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.587600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.483600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.499500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.451800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>61</td>\n",
              "      <td>1.520500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>62</td>\n",
              "      <td>1.482000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>1.498700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>64</td>\n",
              "      <td>1.373400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>1.378700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>1.608800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>67</td>\n",
              "      <td>1.570600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>68</td>\n",
              "      <td>1.375300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>1.447500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>1.509200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>71</td>\n",
              "      <td>1.582900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>1.481600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>73</td>\n",
              "      <td>1.513300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>74</td>\n",
              "      <td>1.591000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>1.596400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>76</td>\n",
              "      <td>1.576900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>77</td>\n",
              "      <td>1.518800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>1.497100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>79</td>\n",
              "      <td>1.519400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>1.582500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>1.516200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>82</td>\n",
              "      <td>1.614900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>83</td>\n",
              "      <td>1.477600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>1.526500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>1.487000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>86</td>\n",
              "      <td>1.523400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>1.515100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>88</td>\n",
              "      <td>1.586400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>89</td>\n",
              "      <td>1.478200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>1.423000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>91</td>\n",
              "      <td>1.577100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>92</td>\n",
              "      <td>1.413800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>1.535000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>94</td>\n",
              "      <td>1.538900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>1.526200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>1.463500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>97</td>\n",
              "      <td>1.570700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>98</td>\n",
              "      <td>1.500200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>1.651600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.541000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>101</td>\n",
              "      <td>1.423300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>1.484000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>103</td>\n",
              "      <td>1.565200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>104</td>\n",
              "      <td>1.530500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>1.448400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>106</td>\n",
              "      <td>1.495300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>107</td>\n",
              "      <td>1.562100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>1.509100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>109</td>\n",
              "      <td>1.313200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>1.642300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>1.547000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>112</td>\n",
              "      <td>1.536400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>113</td>\n",
              "      <td>1.486300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>1.548900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>1.483700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>116</td>\n",
              "      <td>1.542100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>1.581600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>118</td>\n",
              "      <td>1.521000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>119</td>\n",
              "      <td>1.445200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>1.501400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>121</td>\n",
              "      <td>1.450100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>122</td>\n",
              "      <td>1.569200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>1.468600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URMxsR5JiARA"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(PROJECT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AMFR4e8wH0J"
      },
      "source": [
        "# 3. Predict data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FX7vdPXzwH0K"
      },
      "outputs": [],
      "source": [
        "# model = GemmaModel(\n",
        "#     model_name=\"google/gemma-2b-it\",\n",
        "#     adapter_model_name = CKPT_DIR / PROJECT_NAME,\n",
        "# )\n",
        "\n",
        "prmodel = PRModel(\n",
        "    # model_name = PROJECT,\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    # adapter_model_name = CKPT_DIR / PROJECT_NAME\n",
        "    prompt_builder = prompt_builder,\n",
        ")\n",
        "\n",
        "# test\n",
        "original = \"The competition dataset comprises text passages that have been rewritten by the Gemma LLM according to some rewrite_prompt instruction. The goal of the competition is to determine what prompt was used to rewrite each original text.  Please note that this is a Code Competition. When your submission is scored, this example test data will be replaced with the full test set. Expect roughly 2,000 original texts in the test set.\"\n",
        "rewritten = \"(Verse 1) The text is rewritten, the LLM has spun, With prompts so clever, they've been outrun. The goal is to find, the prompt so bright, To crack the code, and shine the light. (Chorus) Oh, this is a code competition, my dear, With text and prompts, we'll compete. Two thousand texts, a challenge grand, To guess the prompts, hand over hand.(Verse 2) The original text, a treasure lost, The rewrite prompt, a secret to be\"\n",
        "\n",
        "# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "# inputs = tokenizer(\n",
        "# [\n",
        "#     MistralInstructPromptBuilder().create_test_row(original, rewritten),\n",
        "# ], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "# outputs = model.generate(**inputs, max_new_tokens = 100, use_cache = True)\n",
        "# outputs = [outputs[0][len(inputs[\"input_ids\"][0]):], ]\n",
        "# predict = tokenizer.batch_decode(outputs, skip_special_tokens = True)[0]\n",
        "\n",
        "# import re\n",
        "# predict = predict.replace(\"\\\\n\", \"\\n\")\n",
        "# predict = re.sub(r\"^\\s+|\\s+$\", \"\", predict)\n",
        "# if predict.startswith(\"**Rewrite Prompt:**\"):\n",
        "#     predict = predict[len(\"**Rewrite Prompt:**\"):].strip()\n",
        "# print(predict)\n",
        "\n",
        "prmodel.eval()\n",
        "prmodel.predict_prompt(original, rewritten)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfPDbrl7HdR0"
      },
      "source": [
        "## 3.1. Evaluate the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bwCPnKCHEP6"
      },
      "outputs": [],
      "source": [
        "test_predict = []\n",
        "scores = []\n",
        "\n",
        "model.eval()\n",
        "for index, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
        "    try:\n",
        "        prompt = prmodel.predict_prompt(row['original_text'], row['rewritten_text'])\n",
        "    except:\n",
        "        prompt = \"Improve the following text while maintaining the original meaning\"\n",
        "    test_predict.append(prompt)\n",
        "    test_scores = compare_phrases(row['rewrite_prompt'], [prompt, ])\n",
        "    scores.append(test_scores[0])\n",
        "\n",
        "test_df['rewrite_prompt'] = test_predict\n",
        "test_df['score'] = scores\n",
        "test_df.to_csv(DATA_DIR / \"test_data.csv\", index=False)\n",
        "\n",
        "print('\\nTest score stats: ', stats.describe(np.array(scores)))\n",
        "print('\\nMean SCS score: ', np.mean(np.array(scores)))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03333a9a70f84554b5f11e4490479a74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6a77e76130846ce8b771165ad97f18d",
            "placeholder": "​",
            "style": "IPY_MODEL_7e788bbba0864102ad4d4ac49ff6da18",
            "value": " 3200/3200 [00:03&lt;00:00, 1099.35 examples/s]"
          }
        },
        "229cc36fd7e149179c074beac1c05ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8e92d73ea8b54131b3b28e6e8ecb7a77",
              "IPY_MODEL_a1e61850f5f247d0ab7be7094a810dc5",
              "IPY_MODEL_b2b1404b24fa444eb2659caa7b23e5de"
            ],
            "layout": "IPY_MODEL_ff45296d59534ec58ceb575f7e39f49a"
          }
        },
        "30dec4651d0346af9e392ad046d5c8c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "406b2b5a9370425292ff9998a23d9bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e65d58da69d4b21af89afec22c8fe43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68825f73bbcc4727b8c0c932bfdb9f57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb6b4fb9c60402cbbd67c4bc29e8f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7770d1198f0c40ddaae32f36fd4e7bda": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7903e8c3d41740f195ed572f5e5bf2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e788bbba0864102ad4d4ac49ff6da18": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e92d73ea8b54131b3b28e6e8ecb7a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68825f73bbcc4727b8c0c932bfdb9f57",
            "placeholder": "​",
            "style": "IPY_MODEL_30dec4651d0346af9e392ad046d5c8c9",
            "value": "Map: 100%"
          }
        },
        "9788b0e1560845538632289840f9ca3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99ee65ae8bff466883dbb966bcb55535": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1e61850f5f247d0ab7be7094a810dc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99ee65ae8bff466883dbb966bcb55535",
            "max": 3200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7903e8c3d41740f195ed572f5e5bf2cd",
            "value": 3200
          }
        },
        "aebb3b43ccc4440eb831be56cfe19e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7770d1198f0c40ddaae32f36fd4e7bda",
            "max": 3200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9788b0e1560845538632289840f9ca3e",
            "value": 3200
          }
        },
        "b2b1404b24fa444eb2659caa7b23e5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f674070c3f0e4f3695c4c887dcfd2c3a",
            "placeholder": "​",
            "style": "IPY_MODEL_6cb6b4fb9c60402cbbd67c4bc29e8f7c",
            "value": " 3200/3200 [00:00&lt;00:00, 11839.37 examples/s]"
          }
        },
        "b6a77e76130846ce8b771165ad97f18d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6b57bb8140f49179dfa87129762225e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e65d58da69d4b21af89afec22c8fe43",
            "placeholder": "​",
            "style": "IPY_MODEL_c90d0970929948c7962cc8e792936bb0",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "c90d0970929948c7962cc8e792936bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb1f379fc16e491b9743001bc07abd97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6b57bb8140f49179dfa87129762225e",
              "IPY_MODEL_aebb3b43ccc4440eb831be56cfe19e4b",
              "IPY_MODEL_03333a9a70f84554b5f11e4490479a74"
            ],
            "layout": "IPY_MODEL_406b2b5a9370425292ff9998a23d9bb8"
          }
        },
        "f674070c3f0e4f3695c4c887dcfd2c3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff45296d59534ec58ceb575f7e39f49a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
