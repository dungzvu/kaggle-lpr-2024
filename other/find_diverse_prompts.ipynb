{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "public prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"./data/0401/nbroad-v2.csv\")\n",
    "df2 = pd.read_csv(\"./data/0401/gemma_suppl_rewrite.csv\")\n",
    "\n",
    "df2['rewrite_prompt'] = df2['rewrite_prompts']\n",
    "\n",
    "df = pd.concat([df1[['rewrite_prompt']], df2[['rewrite_prompt']]])\n",
    "\n",
    "# df = pd.read_csv(\"./data/0304/seed_final.csv\")\n",
    "\n",
    "df = df[df['rewrite_prompt'].str.split(\" \").apply(len) <= 15]\n",
    "df = df[~df['rewrite_prompt'].str.contains(r\"if|preserving|maintaining|/|\\(|\\.|\\n\", regex=True)]\n",
    "df = df[~df['rewrite_prompt'].str.endswith(\"-\")]\n",
    "df = df[~df['rewrite_prompt'].str.contains(f\"one act|Christianity|back-alley city|first line as|no exceptions|verbs except|with a twist|every moment is|story titled|watched three episodes|being replaced with|make it clear that|character-customization-menu|or another|completely unknown to|but|assuming|various popular franchises\", regex=True)]\n",
    "df['rewrite_prompt'] = df['rewrite_prompt'].str.replace(r\"\\.$\", \"\", regex=True)\n",
    "df['rewrite_prompt'] = df['rewrite_prompt'].apply(lambda x: x.strip())\n",
    "\n",
    "print(df.shape)\n",
    "prompts = df['rewrite_prompt'].tolist()\n",
    "\n",
    "df.iloc[:12]['rewrite_prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dung's prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "specific    135\n",
      "literary    135\n",
      "general     135\n",
      "modern      135\n",
      "Name: count, dtype: int64\n",
      "(540, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "df_prompts = pd.read_csv(\"./data/0408/data/diverse_prompts.csv\")\n",
    "\n",
    "df_prompts['type'].value_counts()\n",
    "# Get the count of each type\n",
    "type_counts = df_prompts['type'].value_counts()\n",
    "\n",
    "# Find the minimum count among the types\n",
    "max_count = max(type_counts)\n",
    "\n",
    "# Create an empty list to store the balanced DataFrame\n",
    "balanced_df = []\n",
    "\n",
    "# Duplicate random rows to balance the count\n",
    "for type_name, count in type_counts.items():\n",
    "    # Get the rows of the current type\n",
    "    type_rows = df_prompts[df_prompts['type'] == type_name]\n",
    "    \n",
    "    # Duplicate random rows from the current type to match the minimum count\n",
    "    duplicated_rows = type_rows.sample(n=max_count - count, replace=True)\n",
    "    \n",
    "    # Append the original and duplicated rows to the balanced DataFrame\n",
    "    balanced_df.append(type_rows)\n",
    "    balanced_df.append(duplicated_rows)\n",
    "\n",
    "# Concatenate the balanced DataFrame\n",
    "balanced_df = pd.concat(balanced_df)\n",
    "\n",
    "# Shuffle the rows of the balanced DataFrame\n",
    "balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Print the count of each type in the balanced DataFrame\n",
    "print(balanced_df['type'].value_counts())\n",
    "print(balanced_df.shape)\n",
    "\n",
    "df_prompts = balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "t5_base = SentenceTransformer('sentence-t5-base')\n",
    "\n",
    "embeddings = t5_base.encode(df['rewrite_prompt'].tolist()).tolist()\n",
    "\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def diverse_subset(vectors, k):\n",
    "    # Convert vectors to numpy array\n",
    "    X = np.array(vectors)\n",
    "    \n",
    "    # Perform K-means clustering\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    # Get the cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    # Find the centroids of each cluster\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    # Initialize a list to store the diverse subset\n",
    "    diverse_subset = []\n",
    "    \n",
    "    # Select one vector from each cluster to include in the diverse subset\n",
    "    for i in range(k):\n",
    "        cluster_indices = np.where(cluster_labels == i)[0]\n",
    "        if len(cluster_indices) > 0:\n",
    "            # Choose a representative vector from the cluster (e.g., centroid)\n",
    "            representative_index = np.argmin(np.linalg.norm(X[cluster_indices] - centroids[i], axis=1))\n",
    "            diverse_subset.append(cluster_indices[representative_index])\n",
    "    \n",
    "    return diverse_subset\n",
    "\n",
    "subset = diverse_subset(embeddings, 4)\n",
    "print(\"Diverse subset:\", len(subset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shuffle = df.iloc[subset].sample(frac=1).reset_index(drop=True)\n",
    "df_shuffle.to_csv(\"./data/0401/nbroad-v2-gemma_suppl_rewrite.csv\", index=False, columns=['rewrite_prompt'])\n",
    "\n",
    "df_shuffle.iloc[0]['rewrite_prompt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build predict datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# df_prompts = pd.read_csv(\"./data/0401/nbroad-v2-gemma_suppl_rewrite.csv\")\n",
    "df_text = pd.read_csv(\"./data/0401/150_suppl_original_text.csv\")\n",
    "df_text = df_text[df_text['original_text'].str.split(\" \").apply(len) <= 100]\n",
    "df_text = df_text[~df_text['original_text'].str.contains(r\"\\[\\w+\\]\", regex=True)]\n",
    "\n",
    "# prompts = df_prompts.iloc[:200]['rewrite_prompt'].tolist()\n",
    "\n",
    "df_rows = []\n",
    "for i, row in df_prompts.iterrows():\n",
    "    texts = df_text.iloc[random.choices(range(len(df_text)), k=2)]['original_text'].to_list()\n",
    "    for t in texts:\n",
    "        df_rows.append({'rewrite_prompt': row['prompt'], 'original_text': t, 'type': row['type']})\n",
    "\n",
    "df = pd.DataFrame(df_rows)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(\"./data/0407/diverse_dataset.csv\", index=False)\n",
    "\n",
    "df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
