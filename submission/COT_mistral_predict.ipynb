{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "423223b5",
   "metadata": {
    "papermill": {
     "duration": 0.010158,
     "end_time": "2024-04-08T15:29:10.255297",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.245139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c5744",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:29:10.276415Z",
     "iopub.status.busy": "2024-04-08T15:29:10.276058Z",
     "iopub.status.idle": "2024-04-08T15:29:10.286430Z",
     "shell.execute_reply": "2024-04-08T15:29:10.285702Z"
    },
    "papermill": {
     "duration": 0.023169,
     "end_time": "2024-04-08T15:29:10.288282",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.265113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "started_time = time.time()\n",
    "time_limit = 8*3600 - 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac9ea54",
   "metadata": {
    "papermill": {
     "duration": 0.009244,
     "end_time": "2024-04-08T15:29:10.306569",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.297325",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af651e8",
   "metadata": {
    "papermill": {
     "duration": 0.008951,
     "end_time": "2024-04-08T15:29:10.324628",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.315677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Unsloth AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb93a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:29:10.344012Z",
     "iopub.status.busy": "2024-04-08T15:29:10.343725Z",
     "iopub.status.idle": "2024-04-08T15:29:10.347639Z",
     "shell.execute_reply": "2024-04-08T15:29:10.346783Z"
    },
    "papermill": {
     "duration": 0.015878,
     "end_time": "2024-04-08T15:29:10.349586",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.333708",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# !pip install -q -U accelerate bitsandbytes transformers pandas tqdm numpy sentence-transformers spacy\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "# !pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "import torch\n",
    "major_version, minor_version = torch.cuda.get_device_capability()\n",
    "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "if major_version >= 8:\n",
    "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
    "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
    "else:\n",
    "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
    "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579bab29",
   "metadata": {
    "papermill": {
     "duration": 0.008978,
     "end_time": "2024-04-08T15:29:10.368668",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.359690",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Offline for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dadf063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:29:10.388974Z",
     "iopub.status.busy": "2024-04-08T15:29:10.388686Z",
     "iopub.status.idle": "2024-04-08T15:33:36.087962Z",
     "shell.execute_reply": "2024-04-08T15:33:36.086724Z"
    },
    "id": "2eSvM9zX_2d3",
    "outputId": "20a2d958-e093-491f-d88b-f22722eb325c",
    "papermill": {
     "duration": 265.712756,
     "end_time": "2024-04-08T15:33:36.090490",
     "exception": false,
     "start_time": "2024-04-08T15:29:10.377734",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# # Install dependencies\n",
    "# !pip install -U accelerate --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# !pip install -U bitsandbytes --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# !pip install -U transformers --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# !pip install -U sentence-transformers --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# !pip install -U peft --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# !pip install -U xformers --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# !pip install -U unsloth --no-index --find-links /kaggle/input/dung-llm-pip\n",
    "# # !pip install --no-build-isolation --no-dependencies --no-index --find-links /kaggle/input/dung-llm-pip /kaggle/input/dung-llm-pip/unsloth-2024.4.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53164367",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:33:36.111218Z",
     "iopub.status.busy": "2024-04-08T15:33:36.110882Z",
     "iopub.status.idle": "2024-04-08T15:33:46.629434Z",
     "shell.execute_reply": "2024-04-08T15:33:46.628422Z"
    },
    "id": "QmUBVEnvCDJv",
    "papermill": {
     "duration": 10.531622,
     "end_time": "2024-04-08T15:33:46.631888",
     "exception": false,
     "start_time": "2024-04-08T15:33:36.100266",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import time\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    IS_SUBMISSION = True\n",
    "else:\n",
    "    # exit to not waste gpu\n",
    "    IS_SUBMISSION = False\n",
    "\n",
    "# MODEL = 'mistral'\n",
    "MODEL = 'unsloth-mistral'\n",
    "\n",
    "# MODEL_NAME = '/kaggle/input/mistral-7b-instruct-v0.2-bnb-4bit/pytorch/v1/1/mistral-7b-instruct-v0.2-bnb-4bit'\n",
    "# T5_MODEL_NAME = '/kaggle/input/hf-sentence-t5-base/transformers/v1/1/sentence-t5-base'\n",
    "\n",
    "MODEL_NAME = 'unsloth/mistral-7b-instruct-v0.2-bnb-4bit'\n",
    "# MODEL_NAME = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
    "T5_MODEL_NAME = 'sentence-t5-base'\n",
    "\n",
    "#https://github.com/Lightning-AI/lit-gpt/issues/327\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "\n",
    "if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
    "\n",
    "import logging\n",
    "logging.getLogger('transformers').setLevel(logging.ERROR)\n",
    "\n",
    "model, tokenizer = None, None\n",
    "\n",
    "# https://www.kaggle.com/code/curiousprogrammer/entity-extraction-and-classification-using-spacy\n",
    "import spacy\n",
    "# Load the English language model\n",
    "# nlp = spacy.load('/kaggle/input/dung-llm-pip/spacy/en_core_web_sm-3.7.1')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "DATA_PATH = Path('./data')\n",
    "SEED_FILE = DATA_PATH / 'seed.csv'\n",
    "\n",
    "# run scoring in end of script\n",
    "SHOULD_SCORE = False\n",
    "TEST_MODE = True\n",
    "\n",
    "# file to predict\n",
    "if IS_SUBMISSION:\n",
    "    DATA_FILE = \"/kaggle/input/llm-prompt-recovery/test.csv\"\n",
    "else:\n",
    "    DATA_FILE = \"/kaggle/input/llm-prompt-recovery/test.csv\"\n",
    "#     DATA_FILE = \"/kaggle/input/gemma-rewrite-nbroad/nbroad-v2.csv\"\n",
    "#     SHOULD_SCORE = True\n",
    "\n",
    "DATA_FILE = DATA_PATH / 'test.csv'\n",
    "\n",
    "# default prompt\n",
    "baseline_prompt = 'Please improve this text using the writing style with maintaining the original meaning but altering the tone.' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1514d29",
   "metadata": {
    "papermill": {
     "duration": 0.009339,
     "end_time": "2024-04-08T15:33:46.650894",
     "exception": false,
     "start_time": "2024-04-08T15:33:46.641555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c45fcd0",
   "metadata": {
    "papermill": {
     "duration": 0.009069,
     "end_time": "2024-04-08T15:33:46.669466",
     "exception": false,
     "start_time": "2024-04-08T15:33:46.660397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Mistral model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3781f984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:33:46.689740Z",
     "iopub.status.busy": "2024-04-08T15:33:46.688925Z",
     "iopub.status.idle": "2024-04-08T15:33:46.694729Z",
     "shell.execute_reply": "2024-04-08T15:33:46.693885Z"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "925ffbb2-ae84-4c6c-f3e9-6373fb954fc5",
    "papermill": {
     "duration": 0.017911,
     "end_time": "2024-04-08T15:33:46.696601",
     "exception": false,
     "start_time": "2024-04-08T15:33:46.678690",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if MODEL == 'mistral':\n",
    "    from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "    model_name = MODEL_NAME\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Load base model(Mistral 7B)\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit= True,\n",
    "        bnb_4bit_quant_type= \"nf4\",\n",
    "        bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant= False,\n",
    "    )\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            quantization_config=bnb_config,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            device_map=\"auto\",\n",
    "            trust_remote_code=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59233ab",
   "metadata": {
    "papermill": {
     "duration": 0.008974,
     "end_time": "2024-04-08T15:33:46.714715",
     "exception": false,
     "start_time": "2024-04-08T15:33:46.705741",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Unsloth AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad3d78d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:33:46.734550Z",
     "iopub.status.busy": "2024-04-08T15:33:46.734096Z",
     "iopub.status.idle": "2024-04-08T15:35:55.110071Z",
     "shell.execute_reply": "2024-04-08T15:35:55.109194Z"
    },
    "papermill": {
     "duration": 128.391916,
     "end_time": "2024-04-08T15:35:55.115925",
     "exception": false,
     "start_time": "2024-04-08T15:33:46.724009",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "if MODEL == 'unsloth-mistral':\n",
    "    from unsloth import FastLanguageModel\n",
    "    import torch\n",
    "    max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "    dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "    load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "    # 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "#     fourbit_models = [\n",
    "#         \"unsloth/mistral-7b-bnb-4bit\",\n",
    "#         \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
    "#         \"unsloth/llama-2-7b-bnb-4bit\",\n",
    "#         \"unsloth/llama-2-13b-bnb-4bit\",\n",
    "#         \"unsloth/codellama-34b-bnb-4bit\",\n",
    "#         \"unsloth/tinyllama-bnb-4bit\",\n",
    "#         \"unsloth/gemma-7b-bnb-4bit\", # New Google 6 trillion tokens model 2.5x faster!\n",
    "#         \"unsloth/gemma-2b-bnb-4bit\",\n",
    "#     ] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name =  MODEL_NAME,\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "        # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    "    )\n",
    "\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "        model,\n",
    "        r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                        \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "        lora_alpha = 16,\n",
    "        lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "        bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "        use_gradient_checkpointing = True,\n",
    "        random_state = 3407,\n",
    "        use_rslora = False,  # We support rank stabilized LoRA\n",
    "        loftq_config = None, # And LoftQ\n",
    "    )\n",
    "\n",
    "    from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "    tokenizer = get_chat_template(\n",
    "        tokenizer,\n",
    "        chat_template = \"mistral\", # Supports zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, unsloth\n",
    "        # mapping = {\"role\" : \"from\", \"content\" : \"value\", \"user\" : \"human\", \"assistant\" : \"gpt\"}, # ShareGPT style\n",
    "        map_eos_token = True, # Maps <|im_end|> to </s> instead\n",
    "    )\n",
    "\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94019183",
   "metadata": {
    "id": "ekOmTR1hSNcr",
    "papermill": {
     "duration": 0.012497,
     "end_time": "2024-04-08T15:35:55.141133",
     "exception": false,
     "start_time": "2024-04-08T15:35:55.128636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881618e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:35:55.163684Z",
     "iopub.status.busy": "2024-04-08T15:35:55.162977Z",
     "iopub.status.idle": "2024-04-08T15:35:55.186526Z",
     "shell.execute_reply": "2024-04-08T15:35:55.185693Z"
    },
    "papermill": {
     "duration": 0.037027,
     "end_time": "2024-04-08T15:35:55.188593",
     "exception": false,
     "start_time": "2024-04-08T15:35:55.151566",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "seed_content='''rewrite_prompt,original_text,rewritten_text,type,reasoning\n",
    "Revamp this for a historical context.,\"David strolled down the bustling boulevard, mesmerized by the vibrant lights and the lively atmosphere. It was a place where dreams came alive, and he couldn't help but feel alive too.\",\"\"\"A steady twilight bathed the bustling boulevard, casting an ethereal glow upon the opulent architecture and bustling crowd. It was a scene of vibrant life, where aspirations soared and hope danced. David marveled at the spectacle, his heart soaring with the electricity of the moment. The boulevard represented a confluence of dreams, a melting pot of aspirations and aspirations.\"\"\",general,\"Comparing the rewritten text to original text, the rewrite prompt must alter the text by intensifying sensory details and emotions, creating a vivid scene. It retains Irene's interaction with her cat during a thunderstorm, enhancing it with evocative imagery and deeper emotional resonance.\"\n",
    "Reconstruct this text to be more analytical.,\"Dear Dr. Smith,\\n\\nI hope this email finds you well. I wanted to discuss the concept of aggradation in relation to our recent research project. Based on our findings, we observed significant aggradation in the river channel near Kristofer City. I believe this information could be valuable for our upcoming presentation. Would you be available for a quick meeting to further discuss this topic?\\n\\nBest regards,\\nJohn\",\"**Analytical Reconstruction:**\n",
    "\n",
    "**Subject:** Aggradation in River Channel near Kristofer City\n",
    "\n",
    "**Body:**\n",
    "\n",
    "* The email expresses interest in discussing aggradation in the river channel near Kristofer City.\n",
    "* It references the researchers' findings and highlights the observed significant aggradation.\n",
    "* The email requests a meeting to present these findings and explore their implications.\n",
    "* The tone is respectful and professional.\n",
    "\n",
    "**Additional Annotations:**\n",
    "\n",
    "* The email could be framed as a request for collaboration, inviting Dr. Smith to actively participate in the research project.\n",
    "* The focus is on understanding the causes and consequences of aggradation, relating to the researchers' previous work.\n",
    "* The email assumes a positive outcome and seeks Dr. Smith's availability for a meeting.\",general,\"Comparing the rewritten text to original text, the rewrite prompt must alter the text by intensifying the tone and adding urgency, conveying concern in a more assertive manner. It maintains the core elements of expressing care and offering assistance, albeit with a stronger emphasis on urging action and seeking support.\"\n",
    "Revise this text to be more engaging.,\"Martin's room was cluttered with books, clothes, and art supplies, making it a cozy and creative space.\",\"\"\"The walls of Martin's room whispered stories, revealing a haven of creativity nestled amidst the chaos. Artful creations, like a colorful painting dangling above the desk, danced in the gentle light that filtered through the window. Books, like wise travelers, told tales of faraway lands and captivating stories that ignited Martin's imagination. Clothes, like a warm embrace, added a touch of coziness, inviting him to lose himself in the world of creativity.\"\"\",general,\"Comparing the rewritten text to the original text, the rewrite prompt enhances engagement by transforming the description into a vivid narrative with descriptive language, sensory imagery, and metaphorical comparisons, making Martin's room feel more alive and inviting to the reader.\"\n",
    "Refine this text for a journalistic style.,\"Marilyn, a struggling artist, found herself drowning in debt. With her creativity as her only asset, she decided to host an art exhibition. The event was a success, and Marilyn's talent helped her pay off her debts, turning her life around.\",\"\"\"A struggling artist named Marilyn showcased her unwavering spirit through an extraordinary art exhibition that illuminated the local art scene. The vibrant exhibition, which showcased Marilyn's exceptional talent, transformed a bleak chapter in her life.\n",
    "\n",
    "As a canvas, Marilyn displayed her artistic prowess, capturing the essence of life's stories with unparalleled grace. Her artwork, a testament to her resilience, resonated deeply with viewers, captivating their imagination and igniting a spark of hope.\n",
    "\n",
    "The success of the exhibition did not go unnoticed by Marilyn's creditors. They were moved by her unwavering dedication to her craft and the positive impact her art had on the community. With each canvas sold, Marilyn's debts began to dwindle, offering a glimmer of redemption amidst the challenges she had faced.\n",
    "\n",
    "The art exhibition was not just a means to pay off debt but also a testament to Marilyn's unwavering spirit and the boundless power of creativity. Her story touched the hearts of viewers, inspiring them to find solace in the art that transcended material possessions.\n",
    "\n",
    "Marilyn's unwavering commitment to her passion had paid off, not only in terms of financial stability but also in terms of emotional fulfillment. Her art had\",general,\"Comparing the rewritten text to the original text, the rewrite prompt transforms the passage into a journalistic-style narrative by providing detailed descriptions, emphasizing key events, and incorporating quotes or observations from relevant parties. It adds depth and context to Marilyn's story, enhancing its journalistic quality.\"\n",
    "Rewrite this text as if it were spoken word poetry.,\"Lorraine spotted a vibrant rainbow after the storm, filling her heart with joy and hope.\",\"(With a sense of awe and joy)\n",
    "Lorraine, upon the stormy ground,\n",
    "Spotted a rainbow, bright and unbound.\n",
    "The colors danced, a joyous sight,\n",
    "Filling her heart with hope, so bright.\",literary,\"Comparing the rewritten text to the original text, the rewrite prompt transforms the passage into spoken word poetry, characterized by rhythmic language, vivid imagery, and emotional depth. It maintains the essence of Lorraine's experience of joy and hope while enhancing it with poetic elements like metaphor and rhythm.\"\n",
    "Rewrite this text to sound like a sestina.,\"Hey Annette, just wanted to let you know that the deathwatch for Uncle John has been scheduled for tomorrow at 2 pm at St. Mary's Church. It would mean a lot if you could make it. Let me know if you need a ride or any help with anything.\",\"Hey Annette, let me take my cue,\n",
    "For Uncle John's watch is set to cue.\n",
    "At 2 pm tomorrow's the date,\n",
    "St. Mary's Church, a sacred place.\n",
    "If you can be there, come on, don't flake.\n",
    "\n",
    "A ride or a helping hand, I need,\n",
    "To see this through, to make it end.\n",
    "A chance to connect, to lend a hand,\n",
    "To honor a soul who's nearly gone.\n",
    "So please RSVP, Annette, and run and stand.\",literary,\"Comparing the rewritten text to the original text, the rewrite prompt transforms the passage into a sestina, characterized by the repetition of certain words and phrases in a structured manner. It retains the essential information about Uncle John's deathwatch while adhering to the form's rules and poetic structure.\"\n",
    "Rewrite this text to sound like a fable.,\"Stephen gazed at the night sky, mesmerized by the twinkling stars and the vastness of the universe. Astronomy had always been his passion.\",\"\"\"As Stephen watched the twinkling stars dance across the velvety sky that night, he felt his heart ignite with wonder and awe. The vastness of the universe filled him with a sense of cosmic perspective. It was as if he were witnessing an eternal ballet, where the stars gracefully performed their graceful choreographed dance.\"\"\",literary,\"Comparing the rewritten text to the original text, the rewrite prompt transforms the passage into a fable-like narrative, imbuing it with a sense of wonder and whimsy. It retains the essence of Stephen's fascination with astronomy while adding elements of storytelling, metaphor, and a timeless quality reminiscent of traditional fables.\"\n",
    "Revise this text to be a dialogue.,\"Hi Christopher, could you please clarify the usage of the new software? Thank you!\",\"**Christopher:** Hi! Could you please clarify the usage of the new software? Thank you!\n",
    "\n",
    "**You:** Sure, what can I help you with? Let me know if you have any questions.\",literary,\"Comparing the rewritten text to the original text, the rewrite prompt transforms the passage into a dialogue by introducing two characters, Christopher and the speaker (referred to as \"\"You\"\"). It maintains the request for clarification regarding the new software while adding conversational elements and interaction between the characters.\"\n",
    "Rewrite the essay by replacing characters with characters from Lord of the Rings.,\"Hey Denice, just read an interesting article about the benefits of meditation. Thought you might find it helpful!\",\"\"\"Fair enough, Denice. Reading an article about meditation, I see. Though I do find it an intriguing concept, I must confess I find myself somewhat skeptical about the claims it entails. Perhaps I shall explore it further though.\"\"\",specific,\"Comparing the rewritten text to the original text, the rewrite prompt replaces the characters with those from Lord of the Rings, aligning with the directive to rewrite the passage with characters from a specific context. The essence of sharing information remains, albeit with a thematic shift towards a different fictional universe.\"\n",
    "Rewrite this text into the tone of Stranger Things series.,\"Kenneth walked into the store, searching for the perfect peacoat. He found a navy blue one that caught his eye. Trying it on, he admired the tailored fit and warm wool fabric. It was exactly what he needed for the upcoming winter season. Excited, Kenneth made his purchase and left the store, ready to face the cold in style.\",\"(in the tone of Stranger Things): \"\"Kenneth swaggered through the doors, his eyes scanning every inch of the store. He spot a navy peacoat, its allure gleaming in the fluorescent lights. He slipped it on, the tailored fit sending a shiver down his spine. The warm wool hugged him like a cozy blanket, just what the chilly autumn air needed. A giddy grin spread across his face as he grabbed his purchase and sprinted out, ready to face the impending frosty season in style.\"\"\",specific,\"Comparing the rewritten text to the original text, the rewrite prompt aligns with the Stranger Things series by infusing it with the show's tone and atmosphere. It transforms the mundane act of purchasing a peacoat into a dramatic and exhilarating scene reminiscent of the series' adventurous spirit and 80s nostalgia.\"\n",
    "Reframe this text into the tone of The Hobbit book.,\"Lee, a young entrepreneur, had a brilliant idea for a tech startup. However, he lacked the necessary financing to bring his idea to life. Determined, he pitched his concept to investors, showcasing its potential. Impressed, they agreed to provide the funding he needed. With their support, Lee's startup flourished, becoming a successful venture that changed the tech industry forever.\",\"The sun blazed away, baking the dusty plains as Lee, a knapsack overflowing with an ambitious proposition, approached the boisterous throng. Forthright and fiery, he laid out his concept, a potent elixir he believed could rewrite the very fabric of the tech firmament. It was an audacious proposition, a meteor blazing a trail through the starry desert, but Lee, a phoenix from the ashes of uncertainty, ignited it with his unwavering defiance.\n",
    "\n",
    "Those investors, weathered men with faces etched by the relentless sun, were captivated by Lee's audacity. They saw the gleam of a rare gem, a pearl strung with the threads of innovation. They saw the potential for a supernova, a ripple that could set the tech industry ablaze. They were willing to be struck by that spark, to lend a hand to the nascent flame.\n",
    "\n",
    "With their support, Lee's spark ascended, illuminating the sky with a brilliance that electrified the very fabric of the industry. He became a supernova, a titan of a tech behemoth, forever changing the landscape of the digital world.\",specific,\"Comparing the rewritten text to the original text, the rewrite prompt reframes the passage into the tone of The Hobbit book by incorporating imagery and language reminiscent of the fantasy genre. It transforms Lee's entrepreneurial journey into an epic quest, using metaphors of adventure and heroism to convey his determination and eventual success.\"\n",
    "Rewrite this text into the tone of Inception movie.,\"Hey Mari! Just wanted to share something funny that happened today. So, I was telling my friends about that crazy party we went to last weekend, and you know how I tend to exaggerate things? Well, I may have added a little embellishment to the story. They were cracking up, but I couldn't help but laugh at myself too. Anyway, hope you're having a great day! Let's catch up soon.\",\"Yo Mari, check it, a funny shmee happened to me today! So, I was sittin' around tellin' some of my homies about that crazy party we went to last weekend, man, they was in stitches, man! I swear, I gotta be the life of the party sometimes, bro. I'm just spinnin' yarns, y'know? And lemme tell ya, I had myself laughin' at me own ass, man, it was hilarious! Just think, man, I put a little more sparkle in that story than I usually do, you feel me? Anyway, hope you're rockin' it today, man. We should totally catch up soon and have ourselves a good old-fashioned sittin' chat, man!\",specific,\"Comparing the rewritten text to the original text, the rewrite prompt aligns with the tone of the Inception movie by infusing it with slang, colloquial language, and a sense of casualness. It transforms the mundane conversation into a more dynamic and expressive dialogue, reminiscent of the film's style and atmosphere.\"\n",
    "Modify this for a cooking recipe.,\"During the thunderstorm, Dan and his friends huddled together, laughing and telling stories, creating memories that would last a lifetime.\",\"**Cooking Recipe: Thunderstorms and Tales**\n",
    "\n",
    "Ingredients:\n",
    "\n",
    "* 1 tablespoon olive oil\n",
    "* 1 onion, diced\n",
    "* 1 pound of ground beef\n",
    "* 1 teaspoon dried oregano\n",
    "* 1/2 teaspoon salt\n",
    "* 1/4 teaspoon black pepper\n",
    "* 1 (15-ounce) can diced tomatoes\n",
    "* 1 (15-ounce) can tomato sauce\n",
    "* 1 teaspoon dried thyme\n",
    "* 1 teaspoon dried rosemary\n",
    "* 1/2 teaspoon black peppercorns\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Heat the olive oil in a large skillet over medium heat.\n",
    "2. Add the onion and cook until softened, about 5 minutes.\n",
    "3. Add the ground beef and cook until browned.\n",
    "4. Add the oregano, salt, and black pepper and cook for 1 minute, stirring constantly.\n",
    "5. Add the diced tomatoes, tomato sauce, thyme, and rosemary. Simmer for 15 minutes, or until the beef is cooked through.\n",
    "6. Serve over noodles or rice.\",modern,\"Comparing the rewritten text to the original text, the rewrite prompt completely changes the context from a thunderstorm gathering to a cooking recipe. It transforms the narrative into step-by-step instructions for preparing a dish, utilizing ingredients and cooking techniques instead of describing a social event.\"\n",
    "Revise this text to sound like a speech.,\"Kenneth walked into the store, searching for the perfect peacoat. He found a navy blue one that caught his eye. Trying it on, he admired the tailored fit and warm wool fabric. It was exactly what he needed for the upcoming winter season. Excited, Kenneth made his purchase and left the store, ready to face the cold in style.\",\"\"\"My friends, welcome to the store! I stand here today with an abundance of excitement, for I seek to unveil the perfect peacoat for the upcoming winter season. I wander through the aisles, my eyes scanning the vast array of coats that grace the walls. A sea of navy blue catches my attention, beckoning me in.\n",
    "\n",
    "Its tailored fit and warm wool fabric exude an aura of sophistication. It is a coat that transcends mere fashion; it is a statement piece that imbues any outfit with an unmistakable allure. In this very moment, I know the peacoat shall be my companion, shielding me from the frosty winds that dance outside my window.\n",
    "\n",
    "With a triumphant nod, I complete my purchase. With a flourish, I step outside, ready to face the cold in style and grace. The peacoat, proudly adorning my figure, becomes a testament to my discerning taste and timeless spirit.\",modern,\"Comparing the rewritten text to the original text, the rewrite prompt transforms the passage into a speech by imbuing it with formal language and rhetorical elements. It retains the essence of Kenneth's quest for the perfect peacoat while elevating it into a persuasive and eloquent address to an audience.\"\n",
    "Adapt this for a political commentary.,\"Richard, a skilled fisherman, set out on his boat early in the morning to catch some halibut. After a few hours of patiently waiting, he finally hooked a massive halibut. With a triumphant smile, Richard reeled it in and proudly posed for a photo before releasing it back into the ocean. It was a successful day on the water for Richard and his love for halibut fishing grew even stronger.\",\"The idyllic scene of Richard, the skilled fisherman, enjoying his afternoon on the tranquil waters, serves as a poignant metaphor for the American political landscape. Like his unwavering dedication to his craft, Richard represents the unwavering dedication of conservative ideologies, unwavering in their pursuit of preserving tradition and values.\n",
    "\n",
    "Yet, as we witness the poignant image of his catch being released back into the ocean, we cannot help but reflect on the underbelly of this seemingly idyllic scene. The release symbolizes the constant struggle between preserving a sense of community and recognizing the need for sustainable growth.\n",
    "\n",
    "Richard's success as a fisherman can be interpreted as a microcosm of the larger political arena, where conservative voices often find a receptive ear. They prioritize hard work, tradition, and a sense of national identity, often at the expense of inclusivity and environmental responsibility.\n",
    "\n",
    "On the other hand, the release also carries a subtle critique of political ideologies that emphasize short-term gains over long-term sustainability. This release highlights the disconnect between rhetoric and action, where political promises often fail to translate into tangible results.\n",
    "\n",
    "By contrasting the image of Richard's triumphant catch with the larger political context, we can begin to delve\",modern,\"Comparing the rewritten text to the original text, the rewrite prompt adapts the passage into a political commentary by using metaphorical language and drawing parallels between Richard's fishing experience and the American political landscape. It retains the essence of Richard's success while framing it within the context of political ideologies and societal issues.\"\n",
    "Refine this for a financial analysis.,\"Martin's room was cluttered with books, clothes, and art supplies, making it a cozy and creative space.\",\"**Martin's room constitutes a well-maintained personal space, with a significant investment in aesthetics and comfort. While the initial acquisition cost may be higher due to the presence of art supplies and furniture, the long-term value generated through increased tenant attraction, reduced vacancy periods, and improved productivity associated with a conducive work environment ultimately outweighs the initial expenses.**\",modern,\"Comparing the rewritten text to the original text, the rewrite prompt reframes the description of Martin's room into a financial analysis by focusing on its potential return on investment. It emphasizes the value of the items in Martin's room in terms of tenant attraction, reduced vacancy, and increased productivity, aligning with a financial perspective rather than mere description.\"\n",
    "'''\n",
    "\n",
    "with open(SEED_FILE, 'w') as f:\n",
    "    f.write(seed_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d5cb86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:35:55.209415Z",
     "iopub.status.busy": "2024-04-08T15:35:55.208599Z",
     "iopub.status.idle": "2024-04-08T15:35:55.251339Z",
     "shell.execute_reply": "2024-04-08T15:35:55.250383Z"
    },
    "id": "ELiAmo7Kbbad",
    "outputId": "34c3b487-e875-4405-e44b-3fa1b2e24ac7",
    "papermill": {
     "duration": 0.05517,
     "end_time": "2024-04-08T15:35:55.253310",
     "exception": false,
     "start_time": "2024-04-08T15:35:55.198140",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# seed\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "seed_df = pd.read_csv(SEED_FILE)\n",
    "seed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c98994f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:35:55.274145Z",
     "iopub.status.busy": "2024-04-08T15:35:55.273846Z",
     "iopub.status.idle": "2024-04-08T15:35:55.288469Z",
     "shell.execute_reply": "2024-04-08T15:35:55.287577Z"
    },
    "id": "uPXNX_lbZKMn",
    "outputId": "976505e9-e44f-4a28-f5e5-8f2640d2f70c",
    "papermill": {
     "duration": 0.027371,
     "end_time": "2024-04-08T15:35:55.290354",
     "exception": false,
     "start_time": "2024-04-08T15:35:55.262983",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "def get_model_device(model):\n",
    "    return next(model.parameters()).device\n",
    "\n",
    "# Define the text\n",
    "# text = \"Transform the text into a screenplay format, focusing on the scene between Rory and Laura in their bedroom.\"\n",
    "# print(swap_ner([text, ]))\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "def truncate_words(text, max_words=100):\n",
    "    words = text.split()\n",
    "    return ' '.join(words[:max_words])\n",
    "\n",
    "def truncate_words_sentences(text, max_words=100, reverse_counting=False):\n",
    "    doc = nlp(text)\n",
    "    sentences = list([str(s) for s in doc.sents])\n",
    "    if reverse_counting:\n",
    "        sentences = sentences[::-1]\n",
    "\n",
    "#     sentences = text.split('.')\n",
    "#     sentences = [s for s in sentences if s]\n",
    "    truncated_sentences = []\n",
    "    word_count = 0\n",
    "    for sentence in sentences:\n",
    "        truncated_sentences.append(sentence)\n",
    "        n_words = count_words(sentence)\n",
    "        if word_count + n_words > max_words:\n",
    "            break\n",
    "        word_count += n_words\n",
    "    if reverse_counting:\n",
    "        truncated_sentences = truncated_sentences[::-1]\n",
    "    return '.'.join(truncated_sentences) + \".\"\n",
    "\n",
    "def format_rewrite_prompt(text):\n",
    "    while text[-1] in '.!?:,':\n",
    "        text = text[:-1]\n",
    "    return text\n",
    "\n",
    "print(format_rewrite_prompt(\"Rewrite this text,.\"))\n",
    "\n",
    "def get_cot_prompt(row):\n",
    "    user_prompt='Original Text: \"\"\"{}\"\"\"\\n\\nGive me rewrite prompt in 20-word sentence for rewriting the original text into the following rewritten version:\\n\"\"\"{}\"\"\"'\n",
    "    model_prompt='The rewrite prompt is: \"\"\"{prompt}\"\"\". Let\\'s think step by step. {reasoning}.'\n",
    "\n",
    "    t_ = functools.partial(truncate_words_sentences, max_words=200)\n",
    "\n",
    "    return [\n",
    "        {\"role\": \"user\", \"content\": user_prompt.format(t_(row['original_text']), t_(row['rewritten_text'])) },\n",
    "        {\"role\": \"assistant\", \"content\": model_prompt.format(reasoning=format_rewrite_prompt(row['reasoning']), prompt=format_rewrite_prompt(row['rewrite_prompt'])) },\n",
    "    ]\n",
    "\n",
    "def get_prompt(original, rewritten, category='general'):\n",
    "    # rows = [row for _, row in seed_df.iterrows()]\n",
    "    # random.shuffle(rows)\n",
    "    # rows = random.sample(rows, k=8)\n",
    "    # rows = [row for _, row in pd.concat([fixed_seed_df, random_seed_df.sample(1)]).iterrows()]\n",
    "    # system_prompt = \"Provide the new text and I will tell you what new element was added or change in tone was made to improve it - with no references to the original.  I will avoid mentioning names of characters.  It is crucial no person, place or thing from the original text be mentioned.  For example - I will not say things like 'change the puppet show into a book report' - I would just say 'improve this text into a book report'.  If the original text mentions a specific idea, person, place, or thing - I will not mention it in my answer.  For example if there is a 'dog' or 'office' in the original text - the word 'dog' or 'office' must not be in my response.  My answer will be a single sentence.\"\n",
    "    \n",
    "    fixed_seed_df = seed_df[seed_df['type'] == category]\n",
    "    \n",
    "    rows = [row for _, row in fixed_seed_df.iterrows()]\n",
    "    cot = [\n",
    "        # {\"role\": \"assistant\", \"content\": system_prompt}\n",
    "    ]\n",
    "    for row in rows:\n",
    "        cot += get_cot_prompt(row)\n",
    "    user_prompt='Original Text: \"\"\"{}\"\"\"\\n\\nvGive me rewrite prompt in 20-word sentence for rewriting the original text into the following rewritten version:\\n\"\"\"{}\"\"\"'\n",
    "    cot += [\n",
    "        {\"role\": \"user\", \"content\":user_prompt.format(original, rewritten)},\n",
    "        # {\"role\": \"assistant\", \"content\": 'The rewrite prompt is:\"\"\"'},\n",
    "    ]\n",
    "    return cot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46946154",
   "metadata": {
    "papermill": {
     "duration": 0.01003,
     "end_time": "2024-04-08T15:35:55.310034",
     "exception": false,
     "start_time": "2024-04-08T15:35:55.300004",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "T5 Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967f944",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:35:55.376351Z",
     "iopub.status.busy": "2024-04-08T15:35:55.375485Z",
     "iopub.status.idle": "2024-04-08T15:35:59.794419Z",
     "shell.execute_reply": "2024-04-08T15:35:59.793635Z"
    },
    "id": "BgLwSqBdwyek",
    "papermill": {
     "duration": 4.431996,
     "end_time": "2024-04-08T15:35:59.796610",
     "exception": false,
     "start_time": "2024-04-08T15:35:55.364614",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "t5base_model = None\n",
    "\n",
    "def create_t5_model():\n",
    "    global t5base_model\n",
    "    t5base_model = SentenceTransformer(T5_MODEL_NAME)\n",
    "    if torch.cuda.is_available():\n",
    "        t5base_model = t5base_model.to(torch.device(\"cuda\"))\n",
    "    return t5base_model\n",
    "\n",
    "# Function to calculate sharpened cosine similarity\n",
    "def sharpened_cosine_similarity(vec1, vec2, exponent=3):\n",
    "    cosine_similarity = torch.nn.functional.cosine_similarity(vec1, vec2, dim=0)\n",
    "    return cosine_similarity ** exponent\n",
    "\n",
    "#provides similarity scores of a test_phrase against an array of phrases\n",
    "def compare_phrases(test_phrase, phrases):\n",
    "    model = create_t5_model()\n",
    "\n",
    "    scores = []\n",
    "    test_embedding = model.encode(test_phrase, convert_to_tensor=True, show_progress_bar=False)\n",
    "\n",
    "    for phrase in phrases:\n",
    "        compare_embedding = model.encode(phrase, convert_to_tensor=True, show_progress_bar=False)\n",
    "        score = sharpened_cosine_similarity(test_embedding, compare_embedding).item()\n",
    "        scores.append(score)\n",
    "\n",
    "    return scores\n",
    "\n",
    "t5base_model = create_t5_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11553e23",
   "metadata": {},
   "source": [
    "rouge score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e01261",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "\n",
    "# stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# # Function to remove stop words from a text\n",
    "# def remove_stop_words(text):\n",
    "#     word_tokens = word_tokenize(text)\n",
    "#     filtered_text = [word for word in word_tokens if word.casefold() not in stop_words]\n",
    "#     return \" \".join(filtered_text)\n",
    "\n",
    "# def remove_punkt(text):\n",
    "#     word_tokens = word_tokenize(text)\n",
    "#     filtered_text = [word for word in word_tokens if word.isalnum()]\n",
    "#     return \" \".join(filtered_text)\n",
    "\n",
    "\n",
    "# from rouge_score import rouge_scorer\n",
    "# import re\n",
    "\n",
    "\n",
    "# def clean_to_compare(text):\n",
    "#     text = remove_stop_words(text)\n",
    "#     text = remove_punkt(text)\n",
    "\n",
    "#     # remove actions\n",
    "#     text = re.sub(r'^(Convert|Make|Reframe|Adapt|Change|Modify|Transcribe|Translate|Transform|Rephrase|Rewrite|Revise|Edit|Alter|Amend|Adjust|Redraft|Reform|Rescript|Revamp|Vary|Convert|Turn|Transmute|Metamorphose|Metamorphize|Transfigure|Reconstruct|Edit|Add)', '', text)\n",
    "\n",
    "#     # noun\n",
    "#     text = re.sub(r'text|essay|paragraph|passage', '', text)\n",
    "#     text = text.strip()\n",
    "\n",
    "#     return text\n",
    "\n",
    "# scorer_for_rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# def do_rouge_score(text1, text2):\n",
    "#     text1, text2 = list(map(clean_to_compare, [text1, text2]))\n",
    "#     print([text1, text2])\n",
    "#     scores = scorer_for_rouge.score(text1, text2)\n",
    "#     return scores\n",
    "\n",
    "# # Replace these with your sentences\n",
    "# sentences = [\n",
    "#     \"Convert this into a sea shanty\",\n",
    "#     \"Make this a sea shanty\",\n",
    "#     \"Reframe this text to be a sea shanty\",\n",
    "#     \"Edit this passage for better flow and coherence.\",\n",
    "#     \"Transcribe this paragraph into a modern epigram.\"\n",
    "# ]\n",
    "\n",
    "# for s in sentences[1:]:\n",
    "#     scores = do_rouge_score(sentences[0], s)\n",
    "#     print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797baa26",
   "metadata": {
    "papermill": {
     "duration": 0.009472,
     "end_time": "2024-04-08T15:35:59.816266",
     "exception": false,
     "start_time": "2024-04-08T15:35:59.806794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Augment inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01bfedd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:35:59.836926Z",
     "iopub.status.busy": "2024-04-08T15:35:59.836639Z",
     "iopub.status.idle": "2024-04-08T15:35:59.889829Z",
     "shell.execute_reply": "2024-04-08T15:35:59.888858Z"
    },
    "papermill": {
     "duration": 0.065877,
     "end_time": "2024-04-08T15:35:59.891699",
     "exception": false,
     "start_time": "2024-04-08T15:35:59.825822",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "def resample_words(text, step=2):\n",
    "    words = text.split()\n",
    "    return ' '.join(words[::step])\n",
    "\n",
    "def resample_sents(text, step=2):\n",
    "    doc = nlp(text)\n",
    "    sents = list([str(s) for s in doc.sents])\n",
    "    return \" \".join(sents[::step])\n",
    "\n",
    "print(resample_sents(\"Sent1. Sent2. Sent3? Sent4. Sent5\"))\n",
    "\n",
    "def int_to_letter(n):\n",
    "    result = \"\"\n",
    "    while n > 0:\n",
    "        n -= 1\n",
    "        result = chr(ord('A') + n % 26) + result\n",
    "        n //= 26\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "number = 28\n",
    "letter = int_to_letter(number)\n",
    "print(letter)\n",
    "\n",
    "def return_fixed_entity(text, counter, p=0.5):\n",
    "    should_change = random.random() < p\n",
    "    if not should_change:\n",
    "        return text\n",
    "    ls = [\n",
    "        'Andy', 'Cathy', 'New York', 'Paris', 'Apple', 'Google', 'Microsoft', 'Tesla', 'Elon Musk', 'Jeff Bezos',\n",
    "        'China', 'India', 'Japan', 'Germany', 'France', 'Italy', 'Spain', 'United Kingdom', 'Canada', 'Australia',\n",
    "        'Vietnam', 'Thailand', 'Singapore', 'Indonesia', 'Philippines', 'Malaysia', 'South Korea', 'Brazil', 'Mexico',\n",
    "        'Eliza', 'Sophia', 'Olivia', 'Ava', 'Isabella', 'Mia', 'Amelia', 'Harper', 'Evelyn', 'Abigail',\n",
    "        'Peter', 'John', 'James', 'Robert', 'Michael', 'William', 'David', 'Richard', 'Joseph', 'Thomas',\n",
    "    ]\n",
    "    random.shuffle(ls)\n",
    "    if counter >= len(ls):\n",
    "        return text\n",
    "    return ls[counter]\n",
    "\n",
    "def swap_ner(texts):\n",
    "    alias_map = {}\n",
    "    outputs = []\n",
    "    counter = 0\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        new_text = []\n",
    "        for token in doc:\n",
    "            if token.ent_type_ in ['PERSON', 'NORP', 'ORG', 'GPE']:\n",
    "                if token.text not in alias_map:\n",
    "                    alias_map[token.text] = f'{return_fixed_entity(token.text, counter)}'\n",
    "                    counter += 1\n",
    "                new_text.append(alias_map[token.text])\n",
    "            else:\n",
    "                new_text.append(token.text)\n",
    "        outputs.append(' '.join(new_text))\n",
    "    return outputs\n",
    "\n",
    "def gen_more_prompts(prompt):\n",
    "    # gen more prompts by split prompt by ',' and 'and', then make combinations\n",
    "    prompts = []\n",
    "    for p in prompt.split(','):\n",
    "        prompts += p.split(' and ')\n",
    "\n",
    "    prompts = [p for p in prompts if p.strip()]\n",
    "    # make combinations\n",
    "    prefix = prompts[0]\n",
    "    if count_words(prefix) < 6:\n",
    "        return [prefix, ]\n",
    "\n",
    "    prompts = prompts[1:]\n",
    "\n",
    "    new_prompts = [prefix, ]\n",
    "    for i in range(1, len(prompts)+1):\n",
    "        new_prompts += [re.sub(' +', ' ', prefix + ' and ' + ', '.join(comb)) for comb in itertools.combinations(prompts, i)]\n",
    "    return new_prompts\n",
    "\n",
    "print(gen_more_prompts('Rewrite the essay with a new setting and tone, incorporating elements of ancient temples, warriors, and a philosophical theme'))\n",
    "print(gen_more_prompts('Rewrite the essay with a new setting'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97a4e12",
   "metadata": {
    "papermill": {
     "duration": 0.009613,
     "end_time": "2024-04-08T15:35:59.911090",
     "exception": false,
     "start_time": "2024-04-08T15:35:59.901477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "021f14b0",
   "metadata": {
    "papermill": {
     "duration": 0.009425,
     "end_time": "2024-04-08T15:35:59.930162",
     "exception": false,
     "start_time": "2024-04-08T15:35:59.920737",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Perplexity Calc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b90b5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:35:59.951040Z",
     "iopub.status.busy": "2024-04-08T15:35:59.950737Z",
     "iopub.status.idle": "2024-04-08T15:36:03.175294Z",
     "shell.execute_reply": "2024-04-08T15:36:03.174221Z"
    },
    "papermill": {
     "duration": 3.237418,
     "end_time": "2024-04-08T15:36:03.177294",
     "exception": false,
     "start_time": "2024-04-08T15:35:59.939876",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from torch import nn\n",
    "class Perplexity(nn.Module):\n",
    "    def __init__(self, reduce: bool = True):\n",
    "        super().__init__()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        shift_logits = logits[..., :-1, :].contiguous()\n",
    "        shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "        perplexity = []\n",
    "        for i in range(labels.shape[0]):\n",
    "            perplexity.append(self.loss_fn(shift_logits[i], shift_labels[i]))\n",
    "        perplexity = torch.stack(perplexity, dim=0)\n",
    "        #perplexity = torch.exp(perplexity)\n",
    "        if self.reduce:\n",
    "            perplexity = torch.mean(perplexity)\n",
    "        return perplexity \n",
    "    \n",
    "perp = Perplexity()\n",
    "\n",
    "def compute_perplexity(model, tokenizer, samples):\n",
    "    device = get_model_device(model)\n",
    "    \n",
    "    perps = []\n",
    "    with torch.no_grad():\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        inputs = tokenizer(samples, return_tensors=\"pt\", add_special_tokens=False, padding=True, truncation=True).to(device)\n",
    "        output = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        output = output.logits\n",
    "        labels = inputs[\"input_ids\"]\n",
    "        labels.masked_fill_(~inputs[\"attention_mask\"].bool(), -100)\n",
    "        for j in range(len(samples)):\n",
    "            p = perp(output[j].unsqueeze(0), labels[j].unsqueeze(0))\n",
    "            perps.append(p.detach().cpu().float())\n",
    "    return perps\n",
    "\n",
    "print(compute_perplexity(model, tokenizer, [\"Apple is a company in the Korean. It was founded by Steve Jobs.\"]))\n",
    "print(compute_perplexity(model, tokenizer, [\"Apple is a company in the United States. It was founded by Bill Gates.\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cbbea",
   "metadata": {
    "papermill": {
     "duration": 0.009765,
     "end_time": "2024-04-08T15:36:03.197396",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.187631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Post-processing output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d1405",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:36:03.218473Z",
     "iopub.status.busy": "2024-04-08T15:36:03.218171Z",
     "iopub.status.idle": "2024-04-08T15:36:03.638233Z",
     "shell.execute_reply": "2024-04-08T15:36:03.637460Z"
    },
    "papermill": {
     "duration": 0.433164,
     "end_time": "2024-04-08T15:36:03.640360",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.207196",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# post processing essemble\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def choice_prompt(prompts, original_text, rewritten_text):\n",
    "    prompts = [p for p in prompts if len(p) > 0]\n",
    "    if len(prompts) == 0:\n",
    "        return \"\"\n",
    "    if len(prompts) == 1:\n",
    "        return prompts[0]\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    # calc perplexity\n",
    "    perplexity_templ = \"<s> [INST]{prompt}: {original_text}[/INST]{rewritten_text}</s>\"\n",
    "    validate_prompts = [\n",
    "        perplexity_templ.format(prompt=p, original_text=original_text, rewritten_text=rewritten_text) for p in prompts\n",
    "    ]\n",
    "    perps = compute_perplexity(model, tokenizer, validate_prompts)\n",
    "\n",
    "    # print(f'Time to compute perplexity: {time.time() - t} seconds')\n",
    "\n",
    "    if len(prompts) == 2:\n",
    "        return prompts[np.argmin(perps)]\n",
    "\n",
    "    t5base_model = create_t5_model()\n",
    "    vectors = t5base_model.encode(prompts, convert_to_tensor=True, show_progress_bar=False)\n",
    "    X = np.array(vectors.tolist())\n",
    "\n",
    "    # print(f'Time to encode: {time.time() - t} seconds')\n",
    "\n",
    "    n_clusters = min(2, len(prompts))\n",
    "    weights = 1 / (np.array(perps) * np.log(np.array([count_words(p) + 2 for p in prompts])))\n",
    "    # print(f'weights: {weights}')\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(X, sample_weight=weights)\n",
    "    # kmeans.fit(X)\n",
    "\n",
    "    # print(f'Time to clustering: {time.time() - t} seconds')\n",
    "\n",
    "    cluster_labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    \n",
    "    choose_index = 0\n",
    "    largest_cluster_size = 0\n",
    "\n",
    "    for i in range(n_clusters):\n",
    "        cluster_indices = np.where(cluster_labels == i)[0]\n",
    "        # print(cluster_indices)\n",
    "        if len(cluster_indices) > 0:\n",
    "            # Choose a representative vector from the cluster (e.g., centroid)\n",
    "            point_weights = weights[cluster_indices]\n",
    "            representative_index = np.argmax(point_weights)\n",
    "            # representative_index = np.argmax(np.linalg.norm(X[cluster_indices] - centroids[i], axis=1))\n",
    "            # cluster_score = point_weights[representative_index]\n",
    "            cluster_score = np.sum(point_weights)\n",
    "            idx = cluster_indices[representative_index]\n",
    "            if cluster_score > largest_cluster_size:\n",
    "                largest_cluster_size = cluster_score\n",
    "                choose_index = idx\n",
    "\n",
    "    # print(f'Time to choice: {time.time() - t} seconds')\n",
    "    \n",
    "    return prompts[choose_index]\n",
    "\n",
    "# Example usage\n",
    "# choice_prompt([\n",
    "#     \"Rewrite this text into sea shanty\",\n",
    "#     \"Rewrite this text into a poem\",\n",
    "#     \"Rewrite this text into a rhyme\",\n",
    "#     \"Rewrite this text into a essay\",\n",
    "# ], \"Apple is a company in the United States. It was founded by Bill Gates.\", \"(Verse 1) Apple is a company in the United States. It was founded by Bill Gates.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513ea3a5",
   "metadata": {
    "papermill": {
     "duration": 0.009746,
     "end_time": "2024-04-08T15:36:03.660448",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.650702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f922f2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:36:03.681284Z",
     "iopub.status.busy": "2024-04-08T15:36:03.680994Z",
     "iopub.status.idle": "2024-04-08T15:36:03.695478Z",
     "shell.execute_reply": "2024-04-08T15:36:03.694662Z"
    },
    "id": "kMSkkcN3vksN",
    "outputId": "fb2ebe8a-2f4c-4f25-bc4b-ed68d75f503a",
    "papermill": {
     "duration": 0.027076,
     "end_time": "2024-04-08T15:36:03.697349",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.670273",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import functools\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "def get_predict_result(original_text, rewritten_text, return_candidates=False):\n",
    "    # t_ = truncate_words_sentences\n",
    "    t_ = functools.partial(truncate_words_sentences, max_words=200)\n",
    "    # rs2_ = functools.partial(resample_words, step=2)\n",
    "    # rs3_ = functools.partial(resample_words, step=3)\n",
    "    # ner_ = swap_ner\n",
    "\n",
    "    # swap_ner_texts = ner_([t_(original_text, 200), t_(rewritten_text, 200)])\n",
    "\n",
    "#     max_words = min(count_words(original_text), count_words(rewritten_text))\n",
    "\n",
    "    prompts = [\n",
    "        get_prompt(t_(original_text), t_(rewritten_text), 'general'),\n",
    "        get_prompt(t_(original_text), t_(rewritten_text), 'literary'),\n",
    "        get_prompt(t_(original_text), t_(rewritten_text), 'modern'),\n",
    "        get_prompt(t_(original_text), t_(rewritten_text), 'specific'),\n",
    "    ]\n",
    "\n",
    "    tokenized_list = [tokenizer.apply_chat_template(prompt, return_tensors=\"pt\") for prompt in prompts]\n",
    "    max_len = max([tokenized.shape[1] for tokenized in tokenized_list])\n",
    "    encoded = torch.cat([\n",
    "        torch.cat([\n",
    "            t, \n",
    "            torch.full((1, max_len - t.shape[1]), 0)\n",
    "        ], dim=1) for t in tokenized_list\n",
    "    ], dim=0)\n",
    "    # print(encoded.shape)\n",
    "    \n",
    "    model_inputs = encoded.to(device)\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs, \n",
    "        max_new_tokens=30, \n",
    "        do_sample=False,\n",
    "        temperature=0.72,\n",
    "        top_p=0.8,\n",
    "        top_k=10,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    decoded = tokenizer.batch_decode([\n",
    "        generated_ids[i][len(model_inputs[i]):]\n",
    "        for i in range(len(model_inputs))\n",
    "    ])\n",
    "\n",
    "    candidates = [\n",
    "        baseline_prompt,\n",
    "    ]\n",
    "    for output in decoded:\n",
    "        result = output\n",
    "        \n",
    "        # old version\n",
    "        # # get the first sentence\n",
    "        # result = re.split(r\"[!.?:;]+\", result)[0]\n",
    "\n",
    "        # if 'The rewrite prompt is:' in result:\n",
    "        #     result = result.split('The rewrite prompt is:')[1]\n",
    "\n",
    "        # # clean trash tokens\n",
    "        # result = result.split('<s>')[0]\n",
    "        # result = result.split('</s>')[0]\n",
    "        # result = re.sub(r'^[^\\w]+', '', result)\n",
    "        # result = re.sub(r'[^\\w]+$', '', result)\n",
    "        # result = re.sub(r',{2,},\\d+', '', result)\n",
    "        # result = result.strip()\n",
    "        \n",
    "        # if not result.startswith(\"Rewrite\"):\n",
    "        #     result = f\"Rewrite this {result}\"\n",
    "\n",
    "        pattern = r'The rewrite prompt is: \"+([^\"]+)\"+'\n",
    "\n",
    "        texts = re.findall(pattern, result)\n",
    "        \n",
    "        for text in texts:\n",
    "            if count_words(result) < 5:\n",
    "                continue\n",
    "            \n",
    "            # base_prompt = f'Improve this by {result}'\n",
    "            base_prompt = text\n",
    "\n",
    "            if base_prompt:\n",
    "                candidates.append(base_prompt)\n",
    "\n",
    "        # if not base_prompt:\n",
    "        #     print(f'Empty: {output}')\n",
    "        # more_prompts = gen_more_prompts(base_prompt)\n",
    "        # print(f'More prompts: {more_prompts}')\n",
    "        # if base_prompt not in more_prompts:\n",
    "        #     more_prompts.append(base_prompt)\n",
    "        # candidates += more_prompts\n",
    "        \n",
    "    candidates = list(set(candidates))\n",
    "\n",
    "    # print(f'Candidates: {candidates}')\n",
    "    if candidates:\n",
    "        result = choice_prompt(candidates, original_text, rewritten_text)\n",
    "    else:\n",
    "        result = None\n",
    "    # print(f'Choose: {result}')\n",
    "\n",
    "    if return_candidates:\n",
    "        return result, candidates\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaacdf8a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# pattern = r'The rewrite prompt is: \"+(.+)\"+'\n",
    "\n",
    "# text = \"\"\" -- VICE\n",
    "\n",
    "# The rewrite prompt is: \"Transform this text into a descriptive and imaginative narrative.\"\n",
    "\n",
    "# Let's think step\"\"\"\n",
    "\n",
    "# print(re.findall(pattern, text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d70bd5",
   "metadata": {
    "papermill": {
     "duration": 0.009534,
     "end_time": "2024-04-08T15:36:03.716754",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.707220",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Do predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d3139f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:36:03.737614Z",
     "iopub.status.busy": "2024-04-08T15:36:03.737335Z",
     "iopub.status.idle": "2024-04-08T15:36:03.744138Z",
     "shell.execute_reply": "2024-04-08T15:36:03.743235Z"
    },
    "papermill": {
     "duration": 0.019584,
     "end_time": "2024-04-08T15:36:03.746106",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.726522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def trick_for_t5_score(text):\n",
    "    # remove pattern `the/this essay/article/story` from the prompt\n",
    "    match = re.search(r'(the|this) (essay|article|story|text|passage|corpus)', text)\n",
    "    if match and match.start() > 0 and match.start() < len(text)/2:\n",
    "        text = text[:match.start()] + 'this text' + text[match.end():]\n",
    "        \n",
    "    # best mean prefix\n",
    "    text = re.sub(r'^(Rewrite |Convert |Transform |Enhance |Write |Create )', 'Improve ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(trick_for_t5_score(\"Rewrite this essay as a romance\"))\n",
    "print(trick_for_t5_score(\"Write a poem to this essay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea163c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:36:03.767367Z",
     "iopub.status.busy": "2024-04-08T15:36:03.767087Z",
     "iopub.status.idle": "2024-04-08T15:36:17.398162Z",
     "shell.execute_reply": "2024-04-08T15:36:17.397081Z"
    },
    "papermill": {
     "duration": 13.644643,
     "end_time": "2024-04-08T15:36:17.400579",
     "exception": false,
     "start_time": "2024-04-08T15:36:03.755936",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "random.seed(1024)\n",
    "\n",
    "if 'unsloth' in MODEL:\n",
    "    FastLanguageModel.for_inference(model)\n",
    "\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "df = df.iloc[:500]\n",
    "df['original_text'] = df['original_text'].fillna(\"\")\n",
    "df['rewritten_text'] = df['rewritten_text'].fillna(\"\")\n",
    "\n",
    "df_test = df\n",
    "n_samples = len(df_test)\n",
    "\n",
    "TEST_MODE = False\n",
    "\n",
    "if TEST_MODE:\n",
    "    # Test in small dataset\n",
    "    sample_indices = random.sample(range(len(df_test)), min(30, len(df_test)))\n",
    "else:\n",
    "    sample_indices = np.array(range(len(df_test)))\n",
    "\n",
    "print('Predict')\n",
    "predicts = [ baseline_prompt ] * n_samples\n",
    "candidates_list = []\n",
    "\n",
    "t = time.time()\n",
    "# candidates_list = []\n",
    "\n",
    "for i in tqdm.tqdm(sample_indices):\n",
    "    row = df_test.iloc[i]\n",
    "    original_text = row['original_text']\n",
    "    rewritten_text = row['rewritten_text']\n",
    "    result, candidates = get_predict_result(original_text, rewritten_text, return_candidates=True)\n",
    "    candidates_list.append(candidates)\n",
    "    # if 'rewrite_prompt' in row:\n",
    "    #     print(f\"Label: {row['rewrite_prompt']}\")\n",
    "    if not result:\n",
    "        result = baseline_prompt\n",
    "    # predicts.append(result)\n",
    "    predicts[i] = result\n",
    "    \n",
    "    # control time limit. If timeout, all other predict is set to baseline_prompt\n",
    "    if time.time() - started_time > time_limit:\n",
    "        print(f'Timeout, early stop!!!!')\n",
    "        break\n",
    "\n",
    "elapsed_time_per_test = (time.time() - t) / len(sample_indices)\n",
    "print(f\"Estimated {(elapsed_time_per_test * 1500) / 3600} hours for 1500 tests.\")\n",
    "\n",
    "df_test['predict'] = predicts\n",
    "df_test['candidates'] = candidates_list\n",
    "# df_test['predict'] = df_test['predict'].apply(trick_for_t5_score)\n",
    "\n",
    "df_submission = df_test[['id', 'predict']]\n",
    "df_submission['rewrite_prompt'] = df_submission['predict']\n",
    "# df_submission.to_csv(DATA_PATH / 'submission.csv', index=False, columns=['id', 'rewrite_prompt'])\n",
    "df_submission.to_csv('./data/predict.csv', index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852c9b1a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "df_test['predict'] = predicts\n",
    "df_test['candidates'] = candidates_list\n",
    "# df_test['predict'] = df_test['predict'].apply(trick_for_t5_score)\n",
    "# df_submission.to_csv(DATA_PATH / 'submission.csv', index=False, columns=['id', 'rewrite_prompt'])\n",
    "df_test.to_csv('./data/predict.csv', index=False)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65785b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-08T15:36:17.425916Z",
     "iopub.status.busy": "2024-04-08T15:36:17.425614Z",
     "iopub.status.idle": "2024-04-08T15:36:17.433712Z",
     "shell.execute_reply": "2024-04-08T15:36:17.432937Z"
    },
    "papermill": {
     "duration": 0.022933,
     "end_time": "2024-04-08T15:36:17.435689",
     "exception": false,
     "start_time": "2024-04-08T15:36:17.412756",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "SHOULD_SCORE = True\n",
    "\n",
    "if SHOULD_SCORE:\n",
    "    print('Scoring')\n",
    "    \n",
    "    df_score = df_test.iloc[sample_indices]\n",
    "\n",
    "    # calc score\n",
    "    scores = []\n",
    "    for i, row in tqdm.tqdm(df_score.iterrows(), total=df_score.shape[0]):\n",
    "        scores.append(compare_phrases(row['rewrite_prompt'], [row['predict'], ])[0])\n",
    "\n",
    "    df_score['scores'] = scores\n",
    "    df_score.to_csv(DATA_PATH / 'test.csv', index=False)\n",
    "\n",
    "    print('\\nTest score stats: ', stats.describe(np.array(scores)))\n",
    "    print('\\nMean SCS score: ', np.mean(np.array(scores)))\n",
    "\n",
    "    print(df_score.head())\n",
    "    \n",
    "    df_score_sorted = df_score.sort_values('scores')\n",
    "    for _, row in df_score_sorted.iloc[:50].iterrows():\n",
    "        print(f\"------------------------\\n\")\n",
    "        print(f\"Prompt: {row['rewrite_prompt']}\\n\")\n",
    "        print(f\"Predict: {row['predict']}\\n\")\n",
    "        print(f\"Score: {row['scores']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062ba0b",
   "metadata": {
    "papermill": {
     "duration": 0.011459,
     "end_time": "2024-04-08T15:36:17.458758",
     "exception": false,
     "start_time": "2024-04-08T15:36:17.447299",
     "status": "completed"
    },
    "tags": [],
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#  df_score_sorted = df_score.sort_values('scores')\n",
    "for _, row in df_score_sorted.iloc[::-1][:50].iterrows():\n",
    "    print(f\"------------------------\\n\")\n",
    "    print(f\"Prompt: {row['rewrite_prompt']}\\n\")\n",
    "    print(f\"Predict: {row['predict']}\\n\")\n",
    "    print(f\"Rw: {row['rewritten_text'][:100]}\\n\")\n",
    "    print(f\"Score: {row['scores']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4506214,
     "sourceId": 7747717,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 170548727,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 16686,
     "sourceId": 20110,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 16900,
     "sourceId": 20377,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 435.480227,
   "end_time": "2024-04-08T15:36:21.224752",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-04-08T15:29:05.744525",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
