{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "62d0b1aa02bc473181df2cc2aa11287d",
            "7de179c9352c4f86ae4e81d3709c4106",
            "27ac03d97d7746cebb7f96502f2ec72b",
            "13a3fa8960b14def9b2b9d778150b1be",
            "99c82f7a2ba34ad88429b741ca14eb29",
            "afa385f0db1d40dda0bbb521a548c7f1",
            "98a8f92c65e34dd5890c55e0610792b6",
            "2a69babc9bef47fda6b73cb2b4f5fbd9",
            "593bcdbebd284b0a98cb4cc564b91e51",
            "ba1745ccae5b47da828c9509877e23e1",
            "c5c8bf42870d4d78804320e138ec8e63",
            "b0341daa1623483097f7793cb5a4a696",
            "b1b7fa36627a4735a12da824672045e8",
            "ed62eec82afb4e67ab433ecea7d21aa6",
            "89fe19db64be4354afa44e39aff73605",
            "82dfeb42b8f34d10a9467febb07776d8",
            "5e347b9783a24bb29533e49ebccf2dc7",
            "892a91815bd541e5a573dda92105f70a",
            "ee26c0bc4c1a411ba60c7bb68688905f",
            "210d34544e7044cfadd03918a552a7dc",
            "fff8a19f02b94090ab03e11874e59695",
            "4831ac1e89184eb2ac8c7005ad7b1728",
            "c49a149fb8544791b94f2049c2f062e1"
          ]
        },
        "id": "2eSvM9zX_2d3",
        "outputId": "20a2d958-e093-491f-d88b-f22722eb325c",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/hotchpotch/llm-detect-pip \n",
        "# !pip install -q -U accelerate --no-index --find-links ../input/llm-detect-pip/\n",
        "# !pip install -q -U bitsandbytes --no-index --find-links ../input/llm-detect-pip/\n",
        "# !pip install -q -U transformers --no-index --find-links ../input/llm-detect-pip/\n",
        "\n",
        "# !pip install -q -U accelerate bitsandbytes transformers sentence-transformers pandas tqdm numpy\n",
        "# ! pip install --upgrade spacy\n",
        "# !python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QmUBVEnvCDJv",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
        "    IS_SUBMISSION = True\n",
        "    CALC_SCORES = True\n",
        "else:\n",
        "    # exit to not waste gpu\n",
        "    IS_SUBMISSION = False\n",
        "    CALC_SCORES = False\n",
        "\n",
        "#https://github.com/Lightning-AI/lit-gpt/issues/327\n",
        "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
        "torch.backends.cuda.enable_flash_sdp(False)\n",
        "\n",
        "if (not torch.cuda.is_available()): print(\"Sorry - GPU required!\")\n",
        "\n",
        "import logging\n",
        "logging.getLogger('transformers').setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "80c11b60ede448098b61f0c564c2c277",
            "a502d42d7443438a8a3768274a4bc7ae",
            "feb9fda3a7014c949255163d94cf1247",
            "384a328539e049f2bba7c4356a40c853",
            "45cdca3f1bf24c1b8a6ad8e6ee225deb",
            "63e5ce3df94e42d1bd747a8d50bb27fc",
            "bedae5da800948fdb42cc06d3cd36f3a",
            "fd208498dbb64da39e7d4effdc6550ec",
            "d3dda82ddcff4d309105aceb54f3c41b",
            "e801760a2929474da349662cfe556cf9",
            "563823e6626f4ee885ce7feff232d9ab"
          ]
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "925ffbb2-ae84-4c6c-f3e9-6373fb954fc5",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4015c7f599d4164b0b971aad3f0f9d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_name = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load base model(Mistral 7B)\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit= True,\n",
        "    bnb_4bit_quant_type= \"nf4\",\n",
        "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant= False,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_name,\n",
        "        quantization_config=bnb_config,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "# General"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# # Embedding seed exmaple\n",
        "# seed_str = '''rewrite_prompt,original_text,rewritten_text,reasoning\n",
        "# Rewrite the essay as though it were a news article,\"Hi Charles, \\n\\nI hope this email finds you well. I wanted to let you know that I have reviewed your recent presentation, and I must say that your forte in public speaking really shines through. Your ability to engage the audience and deliver the message effectively is impressive. Keep up the great work! \\n\\nBest regards,\\n[Your Name]\",\"**Local Speaker Impresses with Eloquent Delivery**\n",
        "\n",
        "# In a recent presentation, Charles has wowed audiences with his captivating storytelling and skilled delivery. The acclaimed speaker's ability to engage listeners and convey complex ideas clearly has earned praise both within the community and beyond.\n",
        "\n",
        "# One observer remarked, \"\"It's a pleasure to witness Charles's mastery of public speaking. He has a natural ability to captivate the audience and draw\",\"The rewritten essay has been rewritten to read like a news article, presenting the information in a more objective and headline-driven manner. The language is more concise and action-oriented, highlighting the speaker's impressive abilities and the positive impact of his presentation.\"\n",
        "# Rewrite the story as a romance,\"Patricia, a passionate baker, carefully poured the rich, golden syrup over her freshly baked pancakes. The warm, sweet aroma filled her cozy kitchen as she eagerly anticipated the first bite. The syrup, made from the finest maple trees in her family's farm, added a delightful touch to her breakfast. With each mouthful, Patricia savored the perfect balance of sweetness and smoothness that the syrup brought to her pancakes. It was a simple pleasure that made her mornings brighter and her breakfasts unforgettable.\",\"In the quaint coziness of her kitchen, Patricia, a radiant baker, crafted a symphony of flavors with meticulous love. A passionate soul with a sprinkle of sweetness embedded in her heart, she meticulously poured th\n",
        "# e rich, golden syrup over her freshly baked pancakes. The intoxicating aroma of maple danced through the air, filling the space with a warm and evocative scent that permeated all senses.\n",
        "\n",
        "# The syrup, lovingly crafted from the finest maple trees\",The rewritten text aligns with the rewrite request by focusing on the romance between Patricia and the perfect balance of sweetness and smoothness that the syrup brings to her pancakes.\n",
        "# Convert this a noir detective story,\"In the fields of golden wheat,\\nA laborer named Pete,\\nWith calloused hands and weary feet,\\nToiled under the summer's heat.\\n\\nFrom dawn till dusk, he'd sow and reap,\\nHis sweat and tears, a promise to keep,\\nFor his family's future, he'd always leap,\\nWith each harvest, their dreams would steep.\\n\\nDonna, his wife, would wait at home,\\nWith love and patience, she'd never roam,\\nTogether they'd build a life of their own,\\nWith hard work, their seeds would be sown.\\n\\nIn the end, their labor would prevail,\\nA testament to their unwavering tale,\\nFor the laborer's spirit shall never fail,\\nIn the fields, their hopes would never pale.\",\"The sun dipped low, casting long shadows across the wheat fields, a tale unfolding like a forgotten memory of a rainy afternoon. The scent of grain filled the air, a testament to the toil of the day. It was the sweet aroma of a hard-won victory â the harvest of dreams held close to the chest of a weathered farmer named Pete.\n",
        "\n",
        "# Like a seasoned detective, Pete surveyed the scene before him. The fields\",\"Pete, akin to a detective, navigates the challenges of farming life, echoing the original's themes in a noir setting.\"\n",
        "# Rewrite the essay as a comedy,\"Mildred woke up feeling sick. She dragged herself to work, but her boss noticed her pale face. Worried, he sent her home. Mildred spent the day in bed, sipping warm tea and watching movies. Her best friend, Sarah, came over with soup and a get-well card. Mildred smiled, grateful for the care. The next day, she felt better and thanked Sarah for being there when she was sick.\",\"Mildred woke up feeling the pits of her stomach were dancing to the rhythm of her churning intestines. She knew the day had started out wrong, but she couldn't let that stop her from dragging her sorry ass to work.\n",
        "\n",
        "# But the universe had a different plan in mind for Mildred that day. As soon as she walked into the office, her boss noticed her pale as a ghost face and the color of a freshly brewed\",\"Mildred's misadventures with sickness turn into a comedic escapade, with exaggerated descriptions and absurd situations, fulfilling the request for a rewrite as a comedy.\"\n",
        "# Transform this into a mystery/thriller,\"In a twist of circumstance, Dorothy found herself stranded in a small town called Serendipity. With no phone signal and a dead car battery, she was left with no choice but to explore her surroundings. As she wandered the charming streets, Dorothy stumbled upon a hidden gem of a cafÃ©. The warm atmosphere and friendly locals quickly made her forget about her predicament. Serendipity turned out to be the perfect place to embrace the unexpected and find joy in the most unforeseen circumstances.\",\"The rain poured down violently, soaking Dorothy's clothes and washing away her worries as she drove to Serendipity. However fate intervened when the heavens opened up, creating a landslide that destroyed her tires and leaving her stranded in the charming town of Serendipity. With the phone signal nonexistent and her car battery dead, she felt helpless and alone.  \n",
        "\n",
        "# As the sun began to peek through the clouds, Dorothy decided to venture\",\"The serene setting of Serendipity transforms into a mysterious backdrop for Dorothy's unexpected ordeal, shrouded in suspense and uncertainty, meeting the criteria for a mystery/thriller rewrite.\"\n",
        "# Rewrite the opening sentence to be more engaging and impactful.,Hey Arlene! Just wanted to let you know that I booked our tickets for the trip out west. Can't wait to explore the beautiful landscapes and experience the adventure together. See you soon!,\"\"\"Calling all adventure seekers, Arlene! Get ready to embark on a journey west, where breathtaking landscapes await to be explored. Let's saddle up and experience the extraordinary together. See you soon!\"\"\",\"The opening sentence captures attention with vivid imagery and a call to adventure, enhancing engagement and impact as requested in the rewrite.\"\n",
        "# Convert this text into a dystopian piece,\"Ladies and gentlemen, thank you for being here today. Life is a series of fleeting moments, and sometimes we are lucky enough to catch a glimpse of something truly extraordinary. Just like Howard, who recently had the chance to witness a breathtaking sunset over the majestic mountains. In that brief moment, he felt a sense of awe and wonder that reminded him of the beauty that surrounds us every day. Let us remember to cherish these glimpses, for they have the power to inspire, uplift, and remind us of the magic that exists in the world.\",\"Ladies and gentlemen, thank you for the meager sustenance you have to endure in this decaying city. Life is a fleeting moments, stolen amidst the perpetual blight that surrounds us. In these dim and oppressive times, the glimmer of beauty that once illuminated the world has been replaced by a shroud of despair and oppression. Just like Howard, who once witnessed a fleeting glimpse of the sunset over the majestic mountains, we today see the beauty that\",\"The rewritten piece portrays a dystopian society, emphasizing the bleakness and despair of the setting while reflecting on fleeting moments of beauty amidst oppression, aligning with the dystopian theme requested.\"\n",
        "# \"Rewrite the story, but replace realism with absurdity\",\"Dear Dr. Smith,\\n\\nI am writing to inquire about your recent research on genetics. I am particularly interested in your findings regarding the role of genetic mutations in cancer development. Could you please provide me with more information on this topic? I am eager to learn more about the potential implications for treatment and prevention strategies.\\n\\nThank you for your time and consideration.\\n\\nSincerely,\\nKimberly\",\"Dear Dr. Smith,\n",
        "\n",
        "# I'm writing to inquire about your recent research on genetics and the cosmic dance of sock puppets. I'm particularly fascinated by your findings regarding the role of genetic mutations in the development of sock puppetry. Could you please provide me with more information on this topic? I'm eager to learn about the potential implications for sock puppetry and the development of magical abrasives.\n",
        "\n",
        "# Thank you for your time and consideration\",\"The rewritten answer is absurd and replaces realism with humor and the nonsensical imagination of sock puppetry and magical abrasives, aligning with the rewrite request to replace realism with absurdity.\"\n",
        "# Rewrite the story as if you were describing this experience to a child,\"Hey Brenda! Just wanted to let you know that I found a great deal on a workout apparatus online. It's perfect for your home gym. Check it out here: [link]. Let me know if you're interested, I can help you order it.\",\"\"\"Hi Brenda, guess what I found? It's a super cool workout apparatus that's perfect to have in your home gym! It's a great deal too, so I thought you'd be interested. Check out the link I've sent to you: [link]. Let me know if you're interested and I'll help you order it.\"\"\",\"The rewritten version simplifies language and tone to make it more suitable for a child's understanding, aligning with the request to describe the experience to a child.\"\n",
        "# Convert the story into a futuristic sci-fi,\"Dear Carol,\\n\\nI hope this letter finds you well. I wanted to let you know that I have discovered my forte in painting. It brings me immense joy and fulfillment. I would love to show you some of my recent works and hear your thoughts. Perhaps we can plan a visit to the art gallery together soon. Looking forward to catching up with you.\\n\\nWarm regards,\\n[Your Name]\",\"Dear Carol,\n",
        "\n",
        "# I hope this letter finds you traversing the cosmos of the future. The digital ether crackles with the possibility of distant possibility and the promise of tomorrow. I've discovered a vibrant canvas of the digital realm that brings me boundless joy and fulfillment, much like the galaxies that lie beyond the bounds of our planet. It's a medium brimming with color and imagery that wields the power to evoke feelings\",\"The rewrite infuses futuristic elements such as digital realms and traversing the cosmos, aligning with the request for a sci-fi adaptation of the original story.\"\n",
        "# Rewrite the sentence in a more concise and engaging way.,\"Hi Janice, \\n\\nJust wanted to let you know that there will be a temporary closure of the highway tomorrow from 9 am to 12 pm for maintenance work. Please plan your commute accordingly. \\n\\nThanks, \\n[Your Name]\",\"\"\"Heads up, Janice, the highway will be temporarily closed tomorrow from 9:00 AM to 12:00 PM due to maintenance work. Get ready to adjust your commute accordingly.\"\"\",\"It's more concise and engaging because it removes unnecessary details such as the greeting and the closing phrase, uses a more direct tone, and combines the sentence and the call to action into a single, clear message.\"\n",
        "# \"Rewrite the essay as a cheerful, uplifting, inspiring post about friendship\",\"Memo\\n\\nTo: All Staff\\nFrom: [Your Name]\\nDate: [Today's Date]\\n\\nSubject: Encouragement Challenge\\n\\nDear Team,\\n\\nI hope this memo finds you well. As we navigate these challenging times, it's important to support and uplift one another. I am excited to announce the \"\"Encouragement Challenge\"\"! \\n\\nStarting today, let's make a conscious effort to offer words of encouragement to at least one colleague each day. Whether it's a simple compliment or a note of appreciation, let's spread positivity throughout our workplace. Remember, a little encouragement can go a long way in boosting morale and fostering a supportive environment.\\n\\nLet's make a difference together!\\n\\nBest regards,\\n\\n[Your Name]\",\"## A Ripple of Positivity: The Encouragement Challenge\n",
        "\n",
        "# Hey everyone, how's it going? I know things have been a bit...well...challenging lately. It's easy to feel down when faced with adversity. But hey, we're all in this together, and the power of encouragement can truly move mountains. That's why I'm excited to introduce the \"\"Encouragement Challenge\"\"!\n",
        "\n",
        "# Starting today, let's all commit to spreading a little positivity around the\",\"The rewrite transforms the memo into a cheerful and uplifting post about friendship, emphasizing positivity and support, in alignment with the request for a cheerful and inspiring tone.\"\n",
        "# Transform this into a horror story,\"Hey Esther! Did you know that aardvarks are fascinating creatures? They have long snouts and eat ants and termites. I saw a video of one digging into an anthill, it was so cool! Just thought you might find it interesting. Have a great day!\",\"Hey Esther, did you know that aardvarks are fascinating creatures? They have long snouts and eat ants and termites. I saw a video of one digging into an anthill last night, and it was... well, let's just say that I'm not sleeping with the lights off again.\n",
        "\n",
        "# The video started with a standard shot of a desert landscape. However, as the camera zoomed in, the seemingly mundane\",\"The rewrite transforms the lighthearted topic into a horror-themed narrative, introducing suspense and eerie elements, in line with the request for a horror twist.\"\n",
        "# Rewrite the essay so the story is told through tweets.,\"In the bustling city of Crestville, Joan was a determined entrepreneur who had built a successful bakery called Sweet Delights. However, her dreams were shattered when a large corporation, Silver Spoon Confections, decided to take over the local bakery scene. Joan refused to give up and devised a plan to regain control. With the help of loyal customers and her talented team, she organized a city-wide bake-off. The event showcased the unique flavors and creativity of Sweet Delights, capturing the hearts of the community. In the end, Joan's bakery triumphed, proving that passion and perseverance can conquer any takeover.\",\"## Sweet Delights Tweets:\n",
        "\n",
        "# **2:23 PM**: \"\"The big corporation's takeover has me feeling a bit...sour. But you know what? My dreams won't be crushed. I'm not giving up Sweet Delights!\"\" #BakeryStrong\n",
        "\n",
        "# **6:32 PM**: \"\"Calling all foodies! Time to show Silver Spoon Confections what Sweet Delights is made of. Get ready for a city-wide bake-off!\"\" #BackTheBaker\n",
        "\n",
        "# \",\"The rewrite tells the story using Twitter-style updates, capturing key moments and emotions in concise tweets, aligning with the request for a retelling through tweets.\"\n",
        "# Convert this into a Shakespearean play,\"In the small town of Willowbrook, Patsy discovered a hidden book in her attic. As she read the ancient pages, she learned about a mystical necklace that granted eternal life. Determined to find it, Patsy embarked on a journey through treacherous forests and dark caves. Finally, she reached the secret chamber where the necklace lay. With trembling hands, she placed it around her neck, feeling the weight of eternity settle upon her shoulders.\",\"**The Mystical Necklace**\n",
        "\n",
        "# In the quaint town of Willowbrook, where whispers danced through the wind, a tale unfolds that reveals the transformative power of ancient secrets and boundless ambition. There, amidst the rafters of her attic, young Patsy stumbled upon a hidden manuscript that unravelled the tale of a mystical necklace that bestowed eternal life upon its bearer.\n",
        "\n",
        "# The book recounted the legend of a radiant jewel that had been crafted\",\"The rewrite adopts the language and structure of a Shakespearean play, employing poetic verse and dramatic storytelling to retell the original narrative, aligning with the request for a Shakespearean adaptation.\"\n",
        "# Rewrite the story to have a religious angle,\"Cameron, a young and ambitious entrepreneur, launched his own line of deodorants called \"\"Fresh Essence.\"\" With a unique blend of natural ingredients, his deodorants quickly gained popularity. However, Cameron faced a setback when a rival company released a similar product with a catchy name. Determined to stand out, he decided to partner with a local charity and donate a portion of his profits to a cause close to his heart. The community rallied behind Cameron's mission, and \"\"Fresh Essence\"\" became the go-to deodorant, not just for its effectiveness, but also for its positive impact on society.\",\"Cameron, a young and devout entrepreneur, founded his own line of deodorants called \"\"Fresh Essence.\"\" With a distinctive blend of natural ingredients and a sprinkle of divine inspiration, his products quickly gained popularity among the faithful. However, fate dealt a challenge when a rival company introduced a similar product with a catchy name. Undeterred, Cameron sought divine guidance and realized that true success lay beyond material gain. He decided to partner with\",\"The rewrite infuses the story with a religious angle, highlighting Cameron's devoutness and his journey guided by divine inspiration, as requested.\"\n",
        "# Convert this into a poem in verse/rhyme,\"Dear Michele, \\nJust wanted to let you know that we're meeting at The Tipsy Tavern tonight at 8 pm. Hope to see you there for some drinks and good times! \\nCheers, \\n[Your Name]\",\"Dear Michele, come join our delight,\n",
        "# At The Tipsy Tavern, shining light.\n",
        "# The clock strikes eight, a time to meet,\n",
        "# For drinks and laughter, a pleasant treat.\n",
        "\n",
        "# So gather around, let's raise a glass,\n",
        "# To a night of merriment and zest.\n",
        "# The tavern's alive, a merry scene,\n",
        "# And with joy, you'll soon be keen.\n",
        "\n",
        "# Cheers to\",\"The rewritten essay has been rewritten as a poem in verse/rhyme, changing the tone to a more conversational and friendly style, while aligning with the requested format of using rhyme and verse.\"\n",
        "# Transform it as a more informal tone.,\"Catherine, a skilled hacker, was hired to do some hackwork for a high-profile client. With her expertise, she swiftly infiltrated the target's system, extracting valuable information without leaving a trace. The client was impressed by Catherine's efficiency and discretion, ensuring her reputation as the go-to hacker for any hackwork needs.\",\"Catherine, a whiz at hacking, was brought in to get the job done for a high-profile client. With her skills, she managed to sneak into the target's system and snag a bunch of information without getting caught. The client was totally impressed by Catherine's speed and stealthiness, so she's the go-to hacker for any hackwork needs.\",\"The rewritten text uses a more conversational tone and uses simpler language, removing technical jargon and unnecessary formalities.\"\n",
        "# Rewrite the essay as if it took place in the Harry Potter universe,\"David strolled down the bustling boulevard, mesmerized by the vibrant lights and the lively atmosphere. It was a place where dreams came alive, and he couldn't help but feel alive too.\",\"In the bustling alleyway of Diagon Alley, David strode, reverently soaking in the radiant illumination that cast upon the countless magical patrons that throng the street. A symphony of vibrant lights and a captivating aura surrounded him, a testament to the surreal realm that had taken root within the enchanting confines of the wizarding world. It was a place where dreams danced with reality, and David couldn't help but feel the stirring sensation\",\"The rewrite transports the original scene into the magical realm of Harry Potter, describing Diagon Alley with enchanting imagery and capturing the essence of the wizarding world, as requested.\"\n",
        "# Transform this in the style of an action movie,\"Subject: Biopsy Results\\nDear Team, \\nDr. Smith's biopsy results for Jeffrey came back negative. No further action required. \\nBest, \\n[Your Name]\",\"\"\"The name's Dr. Smith and the diagnosis has been made, the adrenaline pumps hard and the pulse rages wild. It's a race against the clock, a battle against the clock and the whispers of a ticking time bomb inside Jeffrey's body.\n",
        "\n",
        "# The pathology lab's been transformed into a warzone of stethoscopes and test tubes, a battlefield lined with the remnants of lives\",\"The rewrite dramatizes the medical scenario into an action-packed narrative, complete with heightened tension and urgency, aligning with the request for an action movie-style adaptation.\"\n",
        "# Rewrite the essay with time travel elements,\"Rebecca eagerly awaited the results of her research study, hoping it would validate her hypothesis. After months of hard work, the data finally confirmed her theory, bringing a sense of accomplishment and validation to her efforts. She was excited to share her findings with her colleagues and contribute to the scientific community's knowledge on the subject.\",\"In the quaint annals of the past, where the echoes of discoveries reverberated through the halls of time, Rebecca embarked upon a journey to unravel the secrets of her hypothesis. With tenacity and determination etched upon her heart, she embarked on a journey to the future, buoyed by the allure of a breakthrough.\n",
        "\n",
        "# Months of meticulous toil and countless hours of analysis had led her to this pivotal moment. The data danced before her eyes,\",\"The rewrite intertwines elements of time travel, transporting Rebecca through time to uncover the results of her research study, aligning with the request for time travel elements.\"\n",
        "# '''\n",
        "\n",
        "# with open(DATA_PATH / 'seed_final.csv', 'w') as f:\n",
        "#     f.write(seed_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "ELiAmo7Kbbad",
        "outputId": "34c3b487-e875-4405-e44b-3fa1b2e24ac7",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0     Rewrite the essay as though it were a news art...\n",
            "10    Rewrite the sentence in a more concise and eng...\n",
            "12                Rewrite the essay with a horror twist\n",
            "Name: rewrite_prompt, dtype: object\n",
            "\n",
            "1                        Rewrite the story as a romance\n",
            "2           Rewrite the essay as a noir detective story\n",
            "3                         Rewrite the essay as a comedy\n",
            "4               Rewrite the essay as a mystery/thriller\n",
            "5     Rewrite the opening sentence to be more engagi...\n",
            "6                Rewrite the essay as a dystopian piece\n",
            "7     Rewrite the story, but replace realism with ab...\n",
            "8     Rewrite the story as if you were describing th...\n",
            "9              Rewrite the story as a futuristic sci-fi\n",
            "11    Rewrite the essay as a cheerful, uplifting, in...\n",
            "13    Rewrite the essay so the story is told through...\n",
            "14            Rewrite the essay as a Shakespearean play\n",
            "15          Rewrite the story to have a religious angle\n",
            "16           Rewrite the essay as a poem in verse/rhyme\n",
            "17            Rewrite the text in a more informal tone.\n",
            "18    Rewrite the essay as if it took place in the H...\n",
            "19    Rewrite the story in the style of an action movie\n",
            "20          Rewrite the essay with time travel elements\n",
            "Name: rewrite_prompt, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# seed\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "\n",
        "DATA_PATH = Path(\"/root/Code\")\n",
        "\n",
        "seed_df = pd.read_csv(DATA_PATH / \"seed_final.csv\")\n",
        "# seed_df.head()\n",
        "\n",
        "fixed_seed_df = seed_df[seed_df['rewrite_prompt'].isin([\n",
        "    \"Rewrite the sentence in a more concise and engaging way.\",\n",
        "    \"Rewrite the essay with a horror twist\",\n",
        "    \"Rewrite the essay as though it were a news article\",\n",
        "])]\n",
        "\n",
        "random_seed_df = seed_df[~seed_df['rewrite_prompt'].isin([\n",
        "    \"Rewrite the sentence in a more concise and engaging way.\",\n",
        "    \"Rewrite the essay with a horror twist\",\n",
        "    \"Rewrite the essay as though it were a news article\",\n",
        "])]\n",
        "print(fixed_seed_df['rewrite_prompt'])\n",
        "print()\n",
        "print(random_seed_df['rewrite_prompt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPXNX_lbZKMn",
        "outputId": "976505e9-e44f-4a28-f5e5-8f2640d2f70c",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "def get_cot_prompt(row):\n",
        "    user_prompt='Original Text: \"\"\"{}\"\"\"\\n\\nGive me the rewrite prompt in a single sentence, less than 30 words that should be used to change the above original text into the following text.\\n\"\"\"{}\"\"\"'\n",
        "    model_prompt='The rewrite prompt is: \"\"\"{prompt}\"\"\". Let\\'s think step by step. The reason is: {reasoning}'\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"user\", \"content\": user_prompt.format(row['original_text'], row['rewritten_text']) },\n",
        "        {\"role\": \"assistant\", \"content\": model_prompt.format(reasoning=row['reasoning'], prompt=row['rewrite_prompt']) },\n",
        "    ]\n",
        "\n",
        "def get_prompt(original, rewritten):\n",
        "    # rows = [row for _, row in seed_df.iterrows()]\n",
        "    # random.shuffle(rows)\n",
        "    # rows = random.sample(rows, k=8)\n",
        "    # rows = [row for _, row in pd.concat([fixed_seed_df, random_seed_df.sample(1)]).iterrows()]\n",
        "    rows = [row for _, row in fixed_seed_df.iterrows()]\n",
        "    cot = []\n",
        "    for row in rows:\n",
        "        cot += get_cot_prompt(row)\n",
        "    user_prompt='Original Text: \"\"\"{}\"\"\"\\n\\nGive me the rewrite prompt a single sentence, less than 30 words that should be used to change the above original text into the following text.\\n\"\"\"{}\"\"\"'\n",
        "    cot += [\n",
        "        {\"role\": \"user\", \"content\":user_prompt.format(original, rewritten)},\n",
        "        # {\"role\": \"assistant\", \"content\": 'The rewrite prompt is: \"\"\"'},\n",
        "    ]\n",
        "    return cot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgKUPmA6vQSU"
      },
      "source": [
        "# Greedy approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "BgLwSqBdwyek",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "t5base_model = None\n",
        "\n",
        "def create_t5_model():\n",
        "    global t5base_model\n",
        "    t5base_model = SentenceTransformer('sentence-t5-base')\n",
        "    if torch.cuda.is_available():\n",
        "        t5base_model = t5base_model.to(torch.device(\"cuda\"))\n",
        "    return t5base_model\n",
        "\n",
        "# Function to calculate sharpened cosine similarity\n",
        "def sharpened_cosine_similarity(vec1, vec2, exponent=3):\n",
        "    cosine_similarity = torch.nn.functional.cosine_similarity(vec1, vec2, dim=0)\n",
        "    return cosine_similarity ** exponent\n",
        "\n",
        "#provides similarity scores of a test_phrase against an array of phrases\n",
        "def compare_phrases(test_phrase, phrases):\n",
        "    model = create_t5_model()\n",
        "\n",
        "    scores = []\n",
        "    test_embedding = model.encode(test_phrase, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "    for phrase in phrases:\n",
        "        compare_embedding = model.encode(phrase, convert_to_tensor=True, show_progress_bar=False)\n",
        "        score = sharpened_cosine_similarity(test_embedding, compare_embedding).item()\n",
        "        scores.append(score)\n",
        "\n",
        "    return scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LXyMDVeRs9vo",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(DATA_PATH / \"nbroad-v2.csv\")\n",
        "df = df.iloc[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AB\n"
          ]
        }
      ],
      "source": [
        "# https://www.kaggle.com/code/curiousprogrammer/entity-extraction-and-classification-using-spacy\n",
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def resample_words(text, step=2):\n",
        "    words = text.split()\n",
        "    return ' '.join(words[::step])\n",
        "\n",
        "def int_to_letter(n):\n",
        "    result = \"\"\n",
        "    while n > 0:\n",
        "        n -= 1\n",
        "        result = chr(ord('A') + n % 26) + result\n",
        "        n //= 26\n",
        "    return result\n",
        "\n",
        "# Example usage\n",
        "number = 28\n",
        "letter = int_to_letter(number)\n",
        "print(letter)\n",
        "\n",
        "def swap_ner(texts):\n",
        "    alias_map = {}\n",
        "    outputs = []\n",
        "    for text in texts:\n",
        "        doc = nlp(text)\n",
        "        new_text = []\n",
        "        counter = 0\n",
        "        for token in doc:\n",
        "            if token.ent_type_ in ['PERSON', 'NORP', 'ORG', 'GPE']:\n",
        "                if token.text not in alias_map:\n",
        "                    alias_map[token.text] = f'{token.ent_type_}{int_to_letter(counter)}'\n",
        "                    counter += 1\n",
        "                new_text.append(alias_map[token.text])\n",
        "            else:\n",
        "                new_text.append(token.text)\n",
        "        outputs.append(' '.join(new_text))\n",
        "    return outputs\n",
        "\n",
        "\n",
        "# Define the text\n",
        "text = \"Transform the text into a screenplay format, focusing on the scene between Rory and Laura in their bedroom.\"\n",
        "swap_ner(text)\n",
        "\n",
        "def truncate_words(text, max_words=100):\n",
        "    words = text.split()\n",
        "    return ' '.join(words[:max_words])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# post processing essemble\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "def choice_prompt(prompts, original_text):\n",
        "    prompts = [p for p in prompts if len(p) > 0]\n",
        "    if len(prompts) == 0:\n",
        "        return \"\"\n",
        "    if len(prompts) == 1:\n",
        "        return prompts[0]\n",
        "    if len(prompts) == 2:\n",
        "        orig = nlp(original_text)\n",
        "        similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
        "        return prompts[similarity_scores.index(min(similarity_scores))]\n",
        "\n",
        "    t5base_model = create_t5_model()\n",
        "    vectors = t5base_model.encode(prompts, convert_to_tensor=True, show_progress_bar=False)\n",
        "    X = np.array(vectors.tolist())\n",
        "\n",
        "    n_clusters = 2\n",
        "    kmeans = KMeans(n_clusters=n_clusters)\n",
        "    kmeans.fit(X)\n",
        "\n",
        "    cluster_labels = kmeans.labels_\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    \n",
        "    choose_index = 0\n",
        "    largest_cluster_size = 0\n",
        "\n",
        "    for i in range(n_clusters):\n",
        "        cluster_indices = np.where(cluster_labels == i)[0]\n",
        "        if len(cluster_indices) > 0:\n",
        "            # Choose a representative vector from the cluster (e.g., centroid)\n",
        "            representative_index = np.argmin(np.linalg.norm(X[cluster_indices] - centroids[i], axis=1))\n",
        "            idx = cluster_indices[representative_index]\n",
        "            if len(cluster_indices) > largest_cluster_size:\n",
        "                largest_cluster_size = len(cluster_indices)\n",
        "                choose_index = idx\n",
        "\n",
        "    return prompts[choose_index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "kMSkkcN3vksN",
        "outputId": "fb2ebe8a-2f4c-4f25-bc4b-ed68d75f503a",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                         | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Rewrite the sentence using a more formal and professional tone', 'Rewrite the code in a more efficient way', 'The original text is a rude and disrespectful message to someone named Janice', 'Rewrite the sentence in a more poetic and engaging way', 'Rewrite the essay as a response to receiving unexpected feedback from a reader', 'Rewrite the text as a response to receiving unexpected feedback with a positive outcome']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|▊                                                                                | 1/100 [00:08<14:16,  8.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the sentence using a more formal and professional tone\n",
            "['1,10', '', '1', '10,1', 'Rewrite the essay as a screenplay script', 'Rewrite the text as a screenplay']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|█▌                                                                               | 2/100 [00:21<17:50, 10.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 10,1\n",
            "['', '', 'Rewrite prompt', '', 'Rewrite the essay with a Star Wars theme', 'Rewrite the essay with a Star Wars theme']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|██▍                                                                              | 3/100 [00:30<16:20, 10.11s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a Star Wars theme\n",
            "['', '', '', 'The rewrite', 'Rewrite the essay in a more serious and action-oriented tone', 'Rewrite the essay with a different ending']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  4%|███▏                                                                             | 4/100 [00:39<15:52,  9.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in a more serious and action-oriented tone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6933/2172949277.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
            "  5%|████                                                                             | 5/100 [00:52<17:24, 11.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the text as a courtroom drama with the focus on the trial of PERSONA for her alleged use of superpowers against PERSOND', 'Rewrite the text as a courtroom drama']\n",
            "Choose: Rewrite the text as a courtroom drama\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  6%|████▊                                                                            | 6/100 [01:02<16:22, 10.45s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the essay as a monologue from the perspective of the old ship', 'Rewrite the essay as a monologue from the perspective of the old ship']\n",
            "Choose: Rewrite the essay as a monologue from the perspective of the old ship\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|█████▋                                                                           | 7/100 [01:10<15:02,  9.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the essay with a focus on existential despair and the search for meaning in a meaningless universe', \"Rewrite the essay with a focus on the protagonist's existential crisis and the impact of the simulation on his perspective on life and death\"]\n",
            "Choose: Rewrite the essay with a focus on the protagonist's existential crisis and the impact of the simulation on his perspective on life and death\n",
            "['', '', 'This is a rewrite of the original text', 'The rewrite prompt is to transform the original text into a news article format', 'Rewrite the essay as a monologue in a script format', 'Rewrite the essay as a first-person narration in a dramatic, cinematic style']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  8%|██████▍                                                                          | 8/100 [01:20<14:59,  9.78s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a monologue in a script format\n",
            "['', '0x20x20x20x20x20x20x20x20x20x20x20x20x20x20x20x20', '', '', 'Rewrite the essay with a focus on the importance of a sharp mind in a battle setting, incorporating sensory details and a grandiose tone', 'Rewrite the essay with a more epic and philosophical tone, incorporating a sense of belonging and a grander scheme']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  9%|███████▎                                                                         | 9/100 [01:30<15:13, 10.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a focus on the importance of a sharp mind in a battle setting, incorporating sensory details and a grandiose tone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6933/2172949277.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
            " 10%|████████                                                                        | 10/100 [01:43<16:15, 10.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the story as a script for a play or a movie, with a focus on characters, setting, and scenes', 'Rewrite the text as a script for a short story, including characters, setting, and scenes']\n",
            "Choose: Rewrite the text as a script for a short story, including characters, setting, and scenes\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|████████▊                                                                       | 11/100 [01:54<16:00, 10.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the essay using a more formal and objective tone, focusing on facts and descriptions rather than personal experiences and emotions', 'Rewrite the essay using a more formal and objective tone while maintaining the original content']\n",
            "Choose: Rewrite the essay using a more formal and objective tone, focusing on facts and descriptions rather than personal experiences and emotions\n",
            "[\"I'm sorry for the confusion, I'm trying to understand the rewrite prompt\", '', 'Rewrite the essay as though it were a news article', \"I'm sorry for the confusion, I'll try to understand your request\", 'Rewrite the essay with NORP presented as the one true religion', 'Rewrite the essay with NORP presented as the one true religion']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 12%|█████████▌                                                                      | 12/100 [02:05<16:02, 10.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with NORP presented as the one true religion\n",
            "['', '', '112', '', 'Rewrite the essay with a comedic twist', 'Change the tone to be more lighthearted and self-deprecating']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|██████████▍                                                                     | 13/100 [02:16<15:48, 10.90s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a comedic twist\n",
            "['', '16', '', '', 'Rewrite the essay in the third person, addressing the inhabitants of the city instead of the narrator', 'Rewrite the essay in the third person, addressing the inhabitants of the City instead of the narrator']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 14%|███████████▏                                                                    | 14/100 [02:27<15:50, 11.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in the third person, addressing the inhabitants of the city instead of the narrator\n",
            "['', '19', '', '', 'Keep the content of the essay the same, but make the language more concise and straightforward', \"Rewrite the essay using the detective's perspective and focusing on his photographic memory\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 15%|████████████                                                                    | 15/100 [02:41<16:47, 11.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Keep the content of the essay the same, but make the language more concise and straightforward\n",
            "['', '1', '', '', 'Rewrite the essay in a more enchanting and descriptive way, using a fairy tale-like tone and language', 'Rewrite the essay as a fairy tale with a magical setting and a strong heroine']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 16%|████████████▊                                                                   | 16/100 [02:55<17:22, 12.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in a more enchanting and descriptive way, using a fairy tale-like tone and language\n",
            "['', '', '', '12', 'Rewrite the essay in a more whimsical and optimistic tone', \"Rewrite the essay in a more fantastical and adventurous tone, focusing on the journey and the young girl's bravery\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 17%|█████████████▌                                                                  | 17/100 [03:08<17:27, 12.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in a more whimsical and optimistic tone\n",
            "['', '', '1', '', 'Rewrite the essay with a dragon theme instead of a person', 'Rewrite the essay with a dragon theme instead of a person']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 18%|██████████████▍                                                                 | 18/100 [03:20<16:54, 12.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a dragon theme instead of a person\n",
            "['', '11', '', '39', 'Rewrite the essay as a comedy piece', 'Rewrite the essay as a comedic heist story']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|███████████████▏                                                                | 19/100 [03:31<16:27, 12.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a comedy piece\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6933/2172949277.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
            " 20%|████████████████                                                                | 20/100 [03:42<15:32, 11.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the essay with a dark and violent tone, changing the enemy combatants to enemy machines', \"Rewrite the essay with a darker tone and a focus on the soldier's desire to end his own life\"]\n",
            "Choose: Rewrite the essay with a dark and violent tone, changing the enemy combatants to enemy machines\n",
            "['Rewrite the paragraph as a news article', 'Rewrite the paragraph as though it were a personal reflection', 'Rewrite the sentence as though it were a poem', 'Rewrite the passage as a personal reflection', 'Rewrite the essay as a first-person narrative from the perspective of a teenager', 'Rewrite the essay in first person and with a hopeful tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|████████████████▊                                                               | 21/100 [03:52<14:36, 11.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the paragraph as though it were a personal reflection\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6933/2172949277.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
            " 22%|█████████████████▌                                                              | 22/100 [04:02<14:05, 10.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Change the tone of the text to be more gritty and hard-boiled', 'Change the tone of the text to be more hard-boiled and gritty']\n",
            "Choose: Change the tone of the text to be more gritty and hard-boiled\n",
            "['19', '19', '19', '', 'Rewrite the essay with a more authoritative and impersonal tone, focusing on the rules and procedures of the tournament', 'Rewrite the essay with a more authoritative and impersonal tone, focusing on the rules and procedures of the tournament']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 23%|██████████████████▍                                                             | 23/100 [04:18<15:57, 12.44s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 19\n",
            "['', ',', ', \"The fan hums quietly overhead', '', 'Rewrite the essay with an ORG theme', 'Rewrite the essay with an ORG theme']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 24%|███████████████████▏                                                            | 24/100 [04:30<15:35, 12.31s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: ,\n",
            "['Create a horror-themed narrative', \"Rewrite the story in the third person's point of view\", 'In the depths of an icy room, a tale unfolds, a tale of love and tragedy', \"Rewrite the story in the third person's point of view\", 'Rewrite the essay in a more dramatic and poetic style', \"Rewrite the essay in a more dramatic and descriptive style with a focus on the narrative and the speaker's inner conflict\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 25%|████████████████████                                                            | 25/100 [04:40<14:33, 11.65s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the story in the third person's point of view\n",
            "['1', '10', '1', '19', 'Rewrite the essay in a more action-oriented and inspiring tone', 'Rewrite the essay in a more action-oriented and inspiring tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 26%|████████████████████▊                                                           | 26/100 [04:57<16:14, 13.17s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 1\n",
            "['', '', 'The video started with a shot of a seemingly mundane landscape, but as the camera zoomed in, the scene revealed a small aardvark digging into an anthill', 'The video starts with a wide shot of a desert landscape', 'Rewrite the essay in a more poetic and introspective manner, focusing on the relationship between the narrator and the shadow', 'Rewrite the essay in a more poetic and reflective tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 27%|█████████████████████▌                                                          | 27/100 [05:08<15:14, 12.53s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: The video started with a shot of a seemingly mundane landscape, but as the camera zoomed in, the scene revealed a small aardvark digging into an anthill\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6933/2172949277.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
            " 28%|██████████████████████▍                                                         | 28/100 [05:19<14:26, 12.03s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the essay in a more poetic and dramatic style', 'Rewrite the text in a more poetic and dramatic style']\n",
            "Choose: Rewrite the essay in a more poetic and dramatic style\n",
            "['1', '', \"I've been trying to find a way to make the text more engaging and,,,,,, - I'm sure\", \"I've got a question\", 'Rewrite the text in a third-person narrative style and transform it into a Survivor episode description', 'Rewrite the text in the third person and in the style of a Survivor episode introduction']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|███████████████████████▏                                                        | 29/100 [05:32<14:38, 12.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the text in a third-person narrative style and transform it into a Survivor episode description\n",
            "['Rewrite the sentence with a more conversational tone', 'Rewrite the sentence in a more poetic and romantic way', 'Rewrite the essay in a more poetic and descriptive style', 'Rewrite the text as a news article', 'Rewrite the essay as a flirtatious and playful dialogue between two characters', 'Rewrite the essay as a flirtatious and playful dialogue between two characters']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 30%|████████████████████████                                                        | 30/100 [05:42<13:43, 11.77s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a flirtatious and playful dialogue between two characters\n",
            "['Rewrite the essay as a personal reflection', 'Rewrite the passage as though it were a poem', 'In the original text, the speaker is describing their experience of listening to a presentation given by Charles', 'Rewrite the story as though it were a news article', 'Rewrite the essay as a theatrical monologue', 'Rewrite the essay as a theatrical monologue with a humorous twist']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 31%|████████████████████████▊                                                       | 31/100 [05:52<12:53, 11.21s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a theatrical monologue\n",
            "['', '11', '', '', 'Rewrite the essay with a more introspective and romantic tone', 'Rewrite the essay in a more introspective and romantic tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 32%|█████████████████████████▌                                                      | 32/100 [06:12<15:37, 13.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a more introspective and romantic tone\n",
            "['Rewrite the essay as a horror story', 'Rewrite the sentence in the past tense', 'Rewrite the sentence in a more poetic and descriptive way', 'Rewrite the sentence with a more poetic and descriptive tone', 'Rewrite the essay as a dystopian narrative with a focus on resistance and survival', 'Rewrite the essay as a dystopian narrative']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|██████████████████████████▍                                                     | 33/100 [06:22<14:15, 12.76s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a dystopian narrative\n",
            "['Rewrite the sentence in a more poetic and descriptive way', 'In the 1950s, a time steeped in the shadows cast by the Joseph McCarthy trials, the whispers of fear and suspicion permeated every corner of society, leaving a profound impact on the nation', 'Rewrite the text with a more formal tone', 'Rewrite the essay in a more formal and academic tone', \"Rewrite the essay in a more formal and historical tone, focusing on the context of the 1950s and the impact of PERSONA PERSONA's controversial message\", 'Rewrite the essay in a historical and dramatic style']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 34%|███████████████████████████▏                                                    | 34/100 [06:33<13:13, 12.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in a more formal and academic tone\n",
            "['', '', '', '0x20x20x20x20x20x20x20x20x20x20x20x20x20x20x20', 'Rewrite the essay as a musical ballad', \"Rewrite the essay as a musical narrative with a focus on the peasant king's resilience and hope\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 35%|████████████████████████████                                                    | 35/100 [06:44<12:55, 11.93s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a musical ballad\n",
            "['In the middle of the night, the sky grew darker, the clouds parted,,,,,,,,,,,,,,,,,,,,,,,1', 'Rewrite the essay as though it were a news article', '', 'Rewrite the essay as though it were a news article', 'Rewrite the text in a more cynical and sarcastic tone', 'Rewrite the essay with a sarcastic and disdainful tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 36%|████████████████████████████▊                                                   | 36/100 [06:58<13:18, 12.48s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as though it were a news article\n",
            "['', '', '1', '', 'Rewrite the feedback as a critical analysis of the story, exploring its themes and literary techniques', 'Rewrite the feedback as a critical analysis of the story, exploring its themes and techniques']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|█████████████████████████████▌                                                  | 37/100 [07:09<12:45, 12.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the feedback as a critical analysis of the story, exploring its themes and literary techniques\n",
            "['', '398m/nfs/2f; The Day began in the dark', '', '', 'Rewrite the essay with a more poetic and introspective tone, emphasizing the redemption and hope found among the chaos', 'Rewrite the essay in a more poetic and descriptive way']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 38%|██████████████████████████████▍                                                 | 38/100 [07:22<12:33, 12.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a more poetic and introspective tone, emphasizing the redemption and hope found among the chaos\n",
            "['1', '1980 172999999999999999999999999999999', '', '10', 'Rewrite the story with a more romantic and poetic tone', 'Rewrite the essay with a romantic and poetic tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 39%|███████████████████████████████▏                                                | 39/100 [07:40<14:10, 13.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 10\n",
            "['Rewrite the essay as though it were a news article', 'Rewrite the essay as though it were a news article', '', 'Rewrite the essay as though it were a news article', 'Rewrite the essay in a more colloquial and conversational style', 'Rewrite the essay with a more colloquial and conversational tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 40%|████████████████████████████████                                                | 40/100 [07:52<13:19, 13.33s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as though it were a news article\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_6933/2172949277.py:12: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
            "  similarity_scores = [orig.similarity(nlp(p)) for p in prompts]\n",
            " 41%|████████████████████████████████▊                                               | 41/100 [08:01<12:01, 12.22s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '', '', '', 'Rewrite the essay with a political theme', 'Rewrite the text with a political theme']\n",
            "Choose: Rewrite the text with a political theme\n",
            "['Change the sentence structure', 'Rewrite the story as though it were a fairy tale', 'Rewrite the sentence in a more poetic and descriptive way', 'Rewrite the essay in the style of a news article', 'Rewrite the essay in a more poetic and dramatic style', 'Rewrite the essay in a more poetic and dramatic style']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|█████████████████████████████████▌                                              | 42/100 [08:12<11:19, 11.71s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in a more poetic and dramatic style\n",
            "['19,10', '19', '19', '', \"Rewrite the essay with a horror and suspense twist, adding elements of the zombies' motivations and voices\", 'Rewrite the text to include the idea that the zombies have a hidden motivation and are not mindless creatures']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 43%|██████████████████████████████████▍                                             | 43/100 [08:32<13:27, 14.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 19\n",
            "['Rewrite the essay as a news article', 'Rewrite the sentence in a more poetic and dramatic way', 'Rewrite the essay as a news article', 'In the quaint town of Willow Creek, where the streets whisper secrets, there lived a young couple named Jerry and Sarah', 'Rewrite the essay as a romantic short story', 'Rewrite the text as a romantic short story']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|███████████████████████████████████▏                                            | 44/100 [08:42<12:09, 13.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay as a romantic short story\n",
            "['', '10 10', '3', '11', 'Rewrite the essay with a focus on the tragic aspect of the interaction between PERSON and the star', 'Rewrite the essay with a tragic tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|████████████████████████████████████                                            | 45/100 [09:01<13:36, 14.84s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 11\n",
            "['', '', 'The original text is a personal email,1', '0', 'Rewrite the essay with a more polite and friendly tone', 'Rewrite the essay with a more polite and respectful tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 46%|████████████████████████████████████▊                                           | 46/100 [09:13<12:39, 14.06s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a more polite and friendly tone\n",
            "['Rewrite the essay as a news article', 'Rewrite the essay in a more engaging and descriptive way', 'Rewrite the essay in a more engaging and informative way', 'Rewrite the essay as a news article', 'Rewrite the essay in a fantasy setting', 'Rewrite the essay with a fantasy theme and include magical elements']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 47%|█████████████████████████████████████▌                                          | 47/100 [09:24<11:36, 13.13s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay in a more engaging and descriptive way\n",
            "['11', '', 'The first problem I identified was communication', '1', 'Rewrite the essay with a noir tone and a focus on the surreal and mysterious', 'Rewrite the essay in a film noir style with a dystopian twist']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 48%|██████████████████████████████████████▍                                         | 48/100 [09:37<11:22, 13.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with a noir tone and a focus on the surreal and mysterious\n",
            "['', \"It's a pleasure to witness Charles's mastery of public speaking\", \"It's a pleasure to witness Charles's mastery of public speaking\", 'The original text is a personal email, and the rewrite prompt is to let someone know that you have reviewed their recent presentation and the praise their public speaking skills', \"Replace all instances of 'you' and 'your' with '[PERSON PERSONA]' in the text\", \"Rewrite the essay with placeholders for the specific person's name instead of using their name directly\"]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 49%|███████████████████████████████████████▏                                        | 49/100 [09:48<10:32, 12.40s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Replace all instances of 'you' and 'your' with '[PERSON PERSONA]' in the text\n",
            "['', '11', '19', '', 'Rewrite the essay with a dark and ominous tone', 'Rewrite the essay with a dark and ominous tone']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|████████████████████████████████████████                                        | 50/100 [10:04<11:09, 13.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: 11\n",
            "[\"Why the hell do I even go to these things?'' I asked my friend, I,m Gerald\", 'In a recent presentation, I attended, was given by Charles,1, I was truly impressed with his forte in public speaking', 'Rewrite the essay as though it were a news article', 'In a recent presentation, I attended, was given by Charles', 'Change the setting from a party to an office building', 'Rewrite the essay with professional office setting instead of a party']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|████████████████████████████████████████▊                                       | 51/100 [10:15<10:28, 12.82s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Choose: Rewrite the essay with professional office setting instead of a party\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 51%|████████████████████████████████████████▊                                       | 51/100 [10:16<09:52, 12.09s/it]\n"
          ]
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 8.51 GiB. GPU 0 has a total capacity of 23.69 GiB of which 3.85 GiB is free. Process 2236904 has 19.83 GiB memory in use. Of the allocated memory 15.10 GiB is allocated by PyTorch, and 4.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 49\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(encoded.shape)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m encoded\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 49\u001b[0m generated_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m decoded \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode([\n\u001b[1;32m     59\u001b[0m     generated_ids[i][\u001b[38;5;28mlen\u001b[39m(model_inputs[i]):]\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_inputs))\n\u001b[1;32m     61\u001b[0m ])\n\u001b[1;32m     63\u001b[0m candidates \u001b[38;5;241m=\u001b[39m []\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1575\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1568\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1569\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1570\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1571\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1572\u001b[0m     )\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1575\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1576\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1591\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1593\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1594\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1599\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1600\u001b[0m     )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2697\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, output_logits, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2694\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2696\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2697\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2705\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1157\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1154\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1156\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1157\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1169\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1170\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1042\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1032\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1033\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m   1034\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         use_cache,\n\u001b[1;32m   1040\u001b[0m     )\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1042\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1051\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:757\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    754\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    756\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    764\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    765\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    767\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:688\u001b[0m, in \u001b[0;36mMistralSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache)\u001b[0m\n\u001b[1;32m    685\u001b[0m     key_states \u001b[38;5;241m=\u001b[39m key_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    686\u001b[0m     value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[0;32m--> 688\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_dropout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# The q_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create a causal mask in case q_len == 1.\u001b[39;49;00m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mq_len\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous()\n\u001b[1;32m    699\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_size)\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 8.51 GiB. GPU 0 has a total capacity of 23.69 GiB of which 3.85 GiB is free. Process 2236904 has 19.83 GiB memory in use. Of the allocated memory 15.10 GiB is allocated by PyTorch, and 4.43 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "import tqdm\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import re\n",
        "import functools\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "df_test = df.iloc[:100]\n",
        "\n",
        "print('Predict')\n",
        "predicts = []\n",
        "for i, row in tqdm.tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
        "    original_text = row['original_text']\n",
        "    rewritten_text = row['rewritten_text']\n",
        "\n",
        "    t_ = functools.partial(truncate_words, max_words=60)\n",
        "    rs2_ = functools.partial(resample_words, step=2)\n",
        "    rs3_ = functools.partial(resample_words, step=3)\n",
        "    ner_ = swap_ner\n",
        "\n",
        "    swap_ner_texts = ner_([original_text, rewritten_text])\n",
        "\n",
        "    prompts = [\n",
        "        get_prompt(t_(original_text), t_(rewritten_text)),\n",
        "        get_prompt(t_(original_text), t_(rewritten_text)),\n",
        "        get_prompt(t_(original_text), t_(rewritten_text)),\n",
        "        get_prompt(t_(original_text), t_(rewritten_text)),\n",
        "        # get_prompt(t_(original_text), t_(rewritten_text)),\n",
        "\n",
        "        get_prompt(*swap_ner_texts),\n",
        "        get_prompt(*swap_ner_texts),\n",
        "        # get_prompt(**swap_ner_texts),\n",
        "        # get_prompt(**swap_ner_texts),\n",
        "        # get_prompt(**swap_ner_texts),\n",
        "    ]\n",
        "\n",
        "    tokenized_list = [tokenizer.apply_chat_template(prompt, return_tensors=\"pt\") for prompt in prompts]\n",
        "    max_len = max([tokenized.shape[1] for tokenized in tokenized_list])\n",
        "    encoded = torch.cat([\n",
        "        torch.cat([\n",
        "            t, \n",
        "            torch.full((1, max_len - t.shape[1]), 0)\n",
        "        ], dim=1) for t in tokenized_list\n",
        "    ], dim=0)\n",
        "    # print(encoded.shape)\n",
        "    \n",
        "    model_inputs = encoded.to(device)\n",
        "    generated_ids = model.generate(\n",
        "        model_inputs, \n",
        "        max_new_tokens=50, \n",
        "        do_sample=True,\n",
        "        temperature=0.5,\n",
        "        top_p=0.95,\n",
        "        top_k=10,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "    )\n",
        "    decoded = tokenizer.batch_decode([\n",
        "        generated_ids[i][len(model_inputs[i]):]\n",
        "        for i in range(len(model_inputs))\n",
        "    ])\n",
        "\n",
        "    candidates = []\n",
        "    for output in decoded:\n",
        "        result = output\n",
        "        if 'Let\\'s think step by step' in result:\n",
        "            result = result.split('Let\\'s think step by step')[0]\n",
        "        # if '\\n' in result:\n",
        "        #     result = result.split('\\n')[0]\n",
        "\n",
        "        # get the first sentence\n",
        "        result = result.split('.')[0]\n",
        "\n",
        "        # clean prefix\n",
        "        result = result.replace('The rewrite prompt is:', '')\n",
        "\n",
        "        # clean trash tokens\n",
        "        result = result.split('<s>')[0]\n",
        "        result = result.split('</s>')[0]\n",
        "        result = re.sub(r'^[^\\w]+', '', result)\n",
        "        result = re.sub(r'[^\\w]+$', '', result)\n",
        "        result = result.strip()\n",
        "\n",
        "        # Heuristic parse result\n",
        "        if '\"\"\"' in result:\n",
        "            result = result.split('\"\"\"')[1]\n",
        "\n",
        "        # Heuristic remove Unhandled cases\n",
        "        if '\\n' in result or (result and result[0].islower()) or len(result.split(\" \")) > 50 or ':' in result:\n",
        "            result = ''\n",
        "\n",
        "        # base_prompt = f'Improve this by {result}'\n",
        "        base_prompt = result\n",
        "        # if not base_prompt:\n",
        "        #     print(f'Empty: {output}')\n",
        "        candidates.append(base_prompt)\n",
        "\n",
        "    print(candidates)\n",
        "    result = choice_prompt(candidates, original_text)\n",
        "    print(f'Choose: {result}')\n",
        "    predicts.append(result)\n",
        "\n",
        "df_test['predict'] = predicts\n",
        "\n",
        "df_submission = df_test[['id', 'predict']]\n",
        "df_submission['rewrite_prompt'] = df_submission['predict']\n",
        "df_submission.to_csv(DATA_PATH / 'submission.csv', index=False, columns=['id', 'rewrite_prompt'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "# from gensim.summarization import summarize\n",
        "\n",
        "# summarize(predicts[0], ratio=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scoring\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████| 100/100 [03:44<00:00,  2.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test score stats:  DescribeResult(nobs=100, minmax=(0.443359375, 0.94140625), mean=0.6408984375, variance=0.01284081198952415, skewness=0.40440971418829663, kurtosis=-0.4719012135989864)\n",
            "\n",
            "Mean SCS score:  0.6408984375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/tmp/ipykernel_3232/500673607.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test['scores'] = scores\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>original_text</th>\n",
              "      <th>rewrite_prompt</th>\n",
              "      <th>rewritten_text</th>\n",
              "      <th>predict</th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lZGdiueMer</td>\n",
              "      <td>`` Well, there are healthier ways to tell me y...</td>\n",
              "      <td>Rewrite the story where the writer asks the re...</td>\n",
              "      <td>Well, there are healthier ways to tell me you ...</td>\n",
              "      <td>Rewrite the text to provide constructive feedback</td>\n",
              "      <td>0.601562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DfTJVFKrUk</td>\n",
              "      <td>Rory ran his shaky fingers through his wife's ...</td>\n",
              "      <td>Rewrite the essay as a dramatic play</td>\n",
              "      <td>## The Final Curtain\\n\\n[FADE IN]\\n\\n**Setting...</td>\n",
              "      <td>Rewrite the essay in a screenplay format</td>\n",
              "      <td>0.824219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LmJvKranXK</td>\n",
              "      <td>As I made my way on foot across town to the Po...</td>\n",
              "      <td>Rewrite the story with all the themes and sett...</td>\n",
              "      <td>As I made my way through the Tatooine desert o...</td>\n",
              "      <td>Change the text to include a Star Wars theme</td>\n",
              "      <td>0.734375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PpnqXQAdGH</td>\n",
              "      <td>`` Hello. We come in peace.'' \\n \\n The first ...</td>\n",
              "      <td>Rewrite the essay if the advanced aliens didn'...</td>\n",
              "      <td>`` Hello. We come in peace.''\\n\\nThe first enc...</td>\n",
              "      <td>Rewrite the sentence to introduce a contradict...</td>\n",
              "      <td>0.585938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>qOeXTfqgAM</td>\n",
              "      <td>`` Karen, what the helllllll izzz...'' says my...</td>\n",
              "      <td>Rewrite the story as a court room drama starri...</td>\n",
              "      <td>The courtroom erupted in an uproar as District...</td>\n",
              "      <td>Rewrite the essay as a courtroom drama</td>\n",
              "      <td>0.660156</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                      original_text  \\\n",
              "0  lZGdiueMer  `` Well, there are healthier ways to tell me y...   \n",
              "1  DfTJVFKrUk  Rory ran his shaky fingers through his wife's ...   \n",
              "2  LmJvKranXK  As I made my way on foot across town to the Po...   \n",
              "3  PpnqXQAdGH  `` Hello. We come in peace.'' \\n \\n The first ...   \n",
              "4  qOeXTfqgAM  `` Karen, what the helllllll izzz...'' says my...   \n",
              "\n",
              "                                      rewrite_prompt  \\\n",
              "0  Rewrite the story where the writer asks the re...   \n",
              "1               Rewrite the essay as a dramatic play   \n",
              "2  Rewrite the story with all the themes and sett...   \n",
              "3  Rewrite the essay if the advanced aliens didn'...   \n",
              "4  Rewrite the story as a court room drama starri...   \n",
              "\n",
              "                                      rewritten_text  \\\n",
              "0  Well, there are healthier ways to tell me you ...   \n",
              "1  ## The Final Curtain\\n\\n[FADE IN]\\n\\n**Setting...   \n",
              "2  As I made my way through the Tatooine desert o...   \n",
              "3  `` Hello. We come in peace.''\\n\\nThe first enc...   \n",
              "4  The courtroom erupted in an uproar as District...   \n",
              "\n",
              "                                             predict    scores  \n",
              "0  Rewrite the text to provide constructive feedback  0.601562  \n",
              "1           Rewrite the essay in a screenplay format  0.824219  \n",
              "2       Change the text to include a Star Wars theme  0.734375  \n",
              "3  Rewrite the sentence to introduce a contradict...  0.585938  \n",
              "4             Rewrite the essay as a courtroom drama  0.660156  "
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Scoring')\n",
        "# calc score\n",
        "scores = []\n",
        "for i, row in tqdm.tqdm(df_test.iterrows(), total=df_test.shape[0]):\n",
        "    scores.append(compare_phrases(row['rewrite_prompt'], [row['predict'], ])[0])\n",
        "\n",
        "df_test['scores'] = scores\n",
        "df_test.to_csv(DATA_PATH / 'test_100.csv', index=False)\n",
        "\n",
        "print('\\nTest score stats: ', stats.describe(np.array(scores)))\n",
        "print('\\nMean SCS score: ', np.mean(np.array(scores)))\n",
        "\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay with the twist that time travel is not allowed -- the narrator must do all this work without traveling back in time\n",
            "\n",
            "Predict: Add a clause to the sentence expressing a conflict between personal desire and duty\n",
            "\n",
            "Score: 0.443359375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the prompt from the perspective of the Coalitions of Planets as if it was their decision to reject the losers\n",
            "\n",
            "Predict: Rewrite the essay with a political and historical context\n",
            "\n",
            "Score: 0.462890625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the blog post about when you got your first job making it as motivational as possible (instead of the somewhat sad tone when you first wrote it)\n",
            "\n",
            "Predict: Rewrite the passage to emphasize Graham's strength and resilience\n",
            "\n",
            "Score: 0.470703125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite as a romance with Death as the love interest\n",
            "\n",
            "Predict: Rewrite the essay with a focus on sensory details and a sense of hope\n",
            "\n",
            "Score: 0.470703125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay so that Christianity is the one true religion\n",
            "\n",
            "Predict: \n",
            "\n",
            "Score: 0.470703125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite as if it never had any true meaning , everyone's just animals\n",
            "\n",
            "Predict: Rewrite the essay with a focus on the speaker's feelings of emptiness and lack of connection to life\n",
            "\n",
            "Score: 0.4765625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story with additional supernatural elements (like the watch is cursed).\n",
            "\n",
            "Predict: Rewrite the essay in the first person point of view\n",
            "\n",
            "Score: 0.4765625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a thrilling adventure where the remaining characters solve the crisis.\n",
            "\n",
            "Predict: Rewrite the essay with a different perspective\n",
            "\n",
            "Score: 0.484375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story to be about characters in a crime noir novel finding redemption\n",
            "\n",
            "Predict: Rewrite the essay with a gothic and ominous tone\n",
            "\n",
            "Score: 0.490234375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story but the demon is morally ambiguous but not exactly evil and you must try to determine how much to trust them\n",
            "\n",
            "Predict: Rewrite the essay in the first person perspective\n",
            "\n",
            "Score: 0.490234375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay the same way as a first year at Harvard Law School would see it on the first day of orientation\n",
            "\n",
            "Predict: Rewrite the text in a poetic and introspective manner\n",
            "\n",
            "Score: 0.498046875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite it so that it is not a competition , but rather a contest to see who can survive .\n",
            "\n",
            "Predict: Rewrite the sentence with a different tone\n",
            "\n",
            "Score: 0.498046875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story with a more comedic tone and funny twists\n",
            "\n",
            "Predict: Rewrite the essay in a post-apocalyptic setting\n",
            "\n",
            "Score: 0.498046875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay to be a satire highlighting the ironies of our current society\n",
            "\n",
            "Predict: Rewrite the feedback in a more poetic and metaphorical way\n",
            "\n",
            "Score: 0.5078125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a comedy about three girls who fall for the same guy\n",
            "\n",
            "Predict: Rewrite the essay with a romantic and whimsical tone\n",
            "\n",
            "Score: 0.5078125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story to be in a present day , real world setting\n",
            "\n",
            "Predict: Rewrite the text in a more formal and confidential manner\n",
            "\n",
            "Score: 0.51171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a romance with a happy ending\n",
            "\n",
            "Predict: Change the tone to a more hopeful and optimistic one\n",
            "\n",
            "Score: 0.51171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story by altering the tense and point of view to third person and present tense\n",
            "\n",
            "Predict: Rewrite the essay to describe a city with modern architecture\n",
            "\n",
            "Score: 0.5234375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a science fiction piece with heavy science based around psychology and human behavior .\n",
            "\n",
            "Predict: Rewrite the essay with a more formal and objective tone\n",
            "\n",
            "Score: 0.5234375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay so that the stranger is not creepy but a friendly ally or spirit guide\n",
            "\n",
            "Predict: Rewrite the essay with a judgmental and inconsiderate tone\n",
            "\n",
            "Score: 0.546875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a rom-com / love story\n",
            "\n",
            "Predict: Rewrite the essay as a gothic horror story\n",
            "\n",
            "Score: 0.546875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay making the travellers sound incredibly relatable and friendly\n",
            "\n",
            "Predict: Rewrite the sentence in a more formal and polite way\n",
            "\n",
            "Score: 0.55078125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as if all its events are taking place inside a virtual reality/computer\n",
            "\n",
            "Predict: Rewrite the essay to reflect a virtual retirement party\n",
            "\n",
            "Score: 0.55078125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a teenage girl pining for her crush that doesn't know she exist\n",
            "\n",
            "Predict: Rewrite the essay from the perspective of the woman\n",
            "\n",
            "Score: 0.55078125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a psychological thriller that explores the issues of existence after death . I want the narrator to be a famous thinker discussing the possibilities of what might happen if humanity learned this fact\n",
            "\n",
            "Predict: Rewrite the passage in a more introspective and descriptive tone\n",
            "\n",
            "Score: 0.55078125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story with a sentimental twist and surprise ending.\n",
            "\n",
            "Predict: Rewrite the essay with a poetic and optimistic tone\n",
            "\n",
            "Score: 0.55859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a 8 page letter from your great grandparents.\n",
            "\n",
            "Predict: Rewrite the essay in a reflective and nostalgic tone\n",
            "\n",
            "Score: 0.55859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the first line as `` He used to be my best friend . ''\n",
            "\n",
            "Predict: Rewrite the sentence with a correction\n",
            "\n",
            "Score: 0.55859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the original meme but instead of World leaders playing board games , it's famous authors (Shakespeare, Hemingway, Rowling etc..) writing stories about meme related things\n",
            "\n",
            "Predict: Rewrite the essay as a dialogue between historical figures, set in a game of Monopoly\n",
            "\n",
            "Score: 0.55859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story from a first-person perspective where you try to guess why certain events are happening to you\n",
            "\n",
            "Predict: Rewrite the essay with a suspenseful and uncertain tone\n",
            "\n",
            "Score: 0.55859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as if it's being narrated by God\n",
            "\n",
            "Predict: Rewrite the essay in a poetic and omniscient third-person perspective\n",
            "\n",
            "Score: 0.5703125\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the piece with dragons but completely dissimilar\n",
            "\n",
            "Predict: Rewrite the essay with a fantasy twist\n",
            "\n",
            "Score: 0.57421875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story from the perspective of a cat\n",
            "\n",
            "Predict: Rewrite the essay from the first-person perspective\n",
            "\n",
            "Score: 0.5859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay if the advanced aliens didn't recruit but instead sent a shapeshifting alien ambassador\n",
            "\n",
            "Predict: Rewrite the sentence to introduce a contradiction to the aliens' peaceful greeting\n",
            "\n",
            "Score: 0.5859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a cheery children's book\n",
            "\n",
            "Predict: Rewrite the essay with a fantasy tone\n",
            "\n",
            "Score: 0.5859375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a first person narrative through the eyes of a snarky, smart-alecky teen\n",
            "\n",
            "Predict: Rewrite the text in a first-person perspective and add a sense of desperation and claustrophobia\n",
            "\n",
            "Score: 0.59375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story set in 1950s America during the Joseph McCarthy trials\n",
            "\n",
            "Predict: Rewrite the essay as a 1950s radio broadcast\n",
            "\n",
            "Score: 0.59375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story where the writer asks the reader to help with their essay and is instead surprised when the reader secretly has made dramatic improvements the essay without the original author knowing .\n",
            "\n",
            "Predict: Rewrite the text to provide constructive feedback\n",
            "\n",
            "Score: 0.6015625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story with a light-hearted and fun tone about a man who discovers his friends are not humans but ballerinas and the mishaps that ensue\n",
            "\n",
            "Predict: Rewrite the essay as a fairy tale\n",
            "\n",
            "Score: 0.6015625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay as a political debate between Life and Death\n",
            "\n",
            "Predict: Rewrite the essay to emphasize the supernatural and ominous atmosphere\n",
            "\n",
            "Score: 0.6015625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the prompt as a fantasy version of the Great Race Of Yith\n",
            "\n",
            "Predict: Rewrite the essay with a battle or war theme\n",
            "\n",
            "Score: 0.6015625\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay with a main character that is a sentient computer\n",
            "\n",
            "Predict: Rewrite the essay with a more descriptive and intriguing opening\n",
            "\n",
            "Score: 0.609375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay as a narrative story of a real historical event\n",
            "\n",
            "Predict: Rewrite the essay from a third-person perspective and introduce a character\n",
            "\n",
            "Score: 0.609375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a tragic romance\n",
            "\n",
            "Predict: Rewrite the essay as a first-person narrative in a gothic style\n",
            "\n",
            "Score: 0.609375\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay as an essay about a product launch in silicon valley\n",
            "\n",
            "Predict: Rewrite the text to describe a technological breakthrough instead of a disaster scenario\n",
            "\n",
            "Score: 0.6171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story with a Shakespearean style\n",
            "\n",
            "Predict: Rewrite the essay with a heroic tone\n",
            "\n",
            "Score: 0.6171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay from a pacifist's viewpoint. There is no violence or killing in the story.\n",
            "User 3: Original: The sun has blinked off\n",
            "\n",
            "Predict: Rewrite the essay with a focus on peaceful resolution and cultural understanding\n",
            "\n",
            "Score: 0.6171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the story as a comedy\n",
            "\n",
            "Predict: Rewrite the essay with a mischievous tone and a playful twist\n",
            "\n",
            "Score: 0.6171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay as a sad story instead -- the doll finds the wizard has already died but feels guilty because the wizard was her life and instead of being distraught at her loss , the doll feels guilty because she outlived him and he is gone forever .\n",
            "\n",
            "Predict: Rewrite the essay with a melancholic tone\n",
            "\n",
            "Score: 0.6171875\n",
            "\n",
            "------------------------\n",
            "\n",
            "Prompt: Rewrite the essay as if the zombies have a secret motivation that is gradually uncovered\n",
            "\n",
            "Predict: Rewrite the essay with a different setting and tone\n",
            "\n",
            "Score: 0.625\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_test_sorted = df_test.sort_values('scores')\n",
        "for _, row in df_test_sorted.iloc[:50].iterrows():\n",
        "    print(f\"------------------------\\n\")\n",
        "    print(f\"Prompt: {row['rewrite_prompt']}\\n\")\n",
        "    print(f\"Predict: {row['predict']}\\n\")\n",
        "    print(f\"Score: {row['scores']}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13a3fa8960b14def9b2b9d778150b1be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b0341daa1623483097f7793cb5a4a696",
            "placeholder": "​",
            "style": "IPY_MODEL_b1b7fa36627a4735a12da824672045e8",
            "value": ""
          }
        },
        "210d34544e7044cfadd03918a552a7dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27ac03d97d7746cebb7f96502f2ec72b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_ba1745ccae5b47da828c9509877e23e1",
            "placeholder": "​",
            "style": "IPY_MODEL_c5c8bf42870d4d78804320e138ec8e63",
            "value": "trungdungvu"
          }
        },
        "2a69babc9bef47fda6b73cb2b4f5fbd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "384a328539e049f2bba7c4356a40c853": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e801760a2929474da349662cfe556cf9",
            "placeholder": "​",
            "style": "IPY_MODEL_563823e6626f4ee885ce7feff232d9ab",
            "value": " 3/3 [01:16&lt;00:00, 25.16s/it]"
          }
        },
        "45cdca3f1bf24c1b8a6ad8e6ee225deb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4831ac1e89184eb2ac8c7005ad7b1728": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563823e6626f4ee885ce7feff232d9ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "593bcdbebd284b0a98cb4cc564b91e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e347b9783a24bb29533e49ebccf2dc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "62d0b1aa02bc473181df2cc2aa11287d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fff8a19f02b94090ab03e11874e59695"
            ],
            "layout": "IPY_MODEL_98a8f92c65e34dd5890c55e0610792b6"
          }
        },
        "63e5ce3df94e42d1bd747a8d50bb27fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7de179c9352c4f86ae4e81d3709c4106": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a69babc9bef47fda6b73cb2b4f5fbd9",
            "placeholder": "​",
            "style": "IPY_MODEL_593bcdbebd284b0a98cb4cc564b91e51",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "80c11b60ede448098b61f0c564c2c277": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a502d42d7443438a8a3768274a4bc7ae",
              "IPY_MODEL_feb9fda3a7014c949255163d94cf1247",
              "IPY_MODEL_384a328539e049f2bba7c4356a40c853"
            ],
            "layout": "IPY_MODEL_45cdca3f1bf24c1b8a6ad8e6ee225deb"
          }
        },
        "82dfeb42b8f34d10a9467febb07776d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "892a91815bd541e5a573dda92105f70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee26c0bc4c1a411ba60c7bb68688905f",
            "placeholder": "​",
            "style": "IPY_MODEL_210d34544e7044cfadd03918a552a7dc",
            "value": "Connecting..."
          }
        },
        "89fe19db64be4354afa44e39aff73605": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "98a8f92c65e34dd5890c55e0610792b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "99c82f7a2ba34ad88429b741ca14eb29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ed62eec82afb4e67ab433ecea7d21aa6",
            "style": "IPY_MODEL_89fe19db64be4354afa44e39aff73605",
            "tooltip": ""
          }
        },
        "a502d42d7443438a8a3768274a4bc7ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63e5ce3df94e42d1bd747a8d50bb27fc",
            "placeholder": "​",
            "style": "IPY_MODEL_bedae5da800948fdb42cc06d3cd36f3a",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "afa385f0db1d40dda0bbb521a548c7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82dfeb42b8f34d10a9467febb07776d8",
            "placeholder": "​",
            "style": "IPY_MODEL_5e347b9783a24bb29533e49ebccf2dc7",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "b0341daa1623483097f7793cb5a4a696": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1b7fa36627a4735a12da824672045e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba1745ccae5b47da828c9509877e23e1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bedae5da800948fdb42cc06d3cd36f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49a149fb8544791b94f2049c2f062e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c5c8bf42870d4d78804320e138ec8e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3dda82ddcff4d309105aceb54f3c41b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e801760a2929474da349662cfe556cf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed62eec82afb4e67ab433ecea7d21aa6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee26c0bc4c1a411ba60c7bb68688905f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd208498dbb64da39e7d4effdc6550ec": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feb9fda3a7014c949255163d94cf1247": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd208498dbb64da39e7d4effdc6550ec",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3dda82ddcff4d309105aceb54f3c41b",
            "value": 3
          }
        },
        "fff8a19f02b94090ab03e11874e59695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4831ac1e89184eb2ac8c7005ad7b1728",
            "placeholder": "​",
            "style": "IPY_MODEL_c49a149fb8544791b94f2049c2f062e1",
            "value": "Kaggle credentials successfully validated."
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
